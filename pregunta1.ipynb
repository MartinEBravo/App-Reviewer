{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\felip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\felip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Librerías\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import seaborn as sns # plotting\n",
    "import string # string manipulation\n",
    "import re # regular expressions\n",
    "import nltk # text manipulation\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from tqdm import trange # progress bar\n",
    "from nltk import tokenize # text manipulation\n",
    "from nltk.corpus import stopwords # text manipulation\n",
    "from nltk.stem import WordNetLemmatizer # text manipulation\n",
    "from nltk.probability import FreqDist # text manipulation\n",
    "from collections import Counter # text manipulation\n",
    "from sklearn.feature_extraction.text import CountVectorizer # text manipulation\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator # wordcloud generator\n",
    "from IPython.display import display # image display\n",
    "from PIL import Image\n",
    "\n",
    "#hito 2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "import joblib # guardar modelos\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propuesta experimental\n",
    "\n",
    "Como propuesta experimental, en este proyecto se hará uso de los métodos de clustering para la pregunta 2 y clasificación para la 1 y 3. Dado que clasificación es un método supervisado, adicionalmente se realizarán pruebas para obtener métricas de desempeño para escoger el mejor método de clasificación, mientras que, para el caso de clustering, al ser no supervisado, se deberán usar métodos para validar los clusters generados.\n",
    "\n",
    "## Pregunta 1\n",
    "\n",
    "Para responder la primera pregunta, se ha realizado un preprocesamiento que consta de, en primer lugar, la conversión del rating a palabras, a modo de limitar las categorías de originalmente 5 a 3. En segundo lugar, se hace la limpieza del dataset de aquellas palabras poco útiles para nuestro propósito, por lo que se filtran números, stopwords y se actualiza todo el texto del dataset de reseñas a minúsculas. Dado que, aún con la conversión de ratings existen categorías que quedan subrepresentadas en comparación a otras, se hace un oversampling basado en el rating de las reseñas para obtener un balanceo de datos para que los modelos generados sean mas correctos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para convertir el rating a palabras\n",
    "def ratingTransform(rating):\n",
    "    if rating <= 2:\n",
    "        return \"NEGATIVE\"\n",
    "    elif rating <= 4:\n",
    "        return \"NEUTRAL\"\n",
    "    else:\n",
    "        return \"POSITIVE\"\n",
    "\n",
    "# funcion para realizar la limpieza del texto en el dataset\n",
    "def clean(review):\n",
    "    review = review.lower()\n",
    "    review = re.sub('[^a-z A-Z 0-9-]+', '', review)\n",
    "    review = \" \".join([word for word in review.split() if word not in stopwords.words('english')])\n",
    "    return review\n",
    "\n",
    "# funcion para hacer oversampling de los datos que se encuentran desbalanceados\n",
    "def oversampling(X,y):\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_resample, y_resample = ros.fit_resample(X, y)\n",
    "    return (X_resample, y_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prosiguiendo con los N-gramas, se verá lo que ocurre con los 1-gramas. Primero, se procede con la vectorización, ya que se quiere convertir el texto a una forma que los algoritmos de aprendizaje que se usarán posteriormente puedan entender y procesar. En este caso, dado que en el preprocesamiento se estableció la necesidad de hacer oversampling a los datos, la vectorización será útil para luego poder hacer dicho oversampling. Finalmente, se realiza la división de los datos entre datos de prueba (con el 33% de los datos destinado para eso) y datos de entrenamiento. Adicionalmente, se usarán funciones extras otorgadas por la librería “joblib”, la cual será de utilidad para guardar los datos procesados, para no tener necesidad de ejecutar todo desde el principio, y asi conservar el entrenamiento. Esto es de especial importancia por lo que se mencionara a continuación.\n",
    "\n",
    "Luego de almacenar la data útil para los algoritmos, se procede con el entrenamiento de los modelos. Para estos, se usarán principalmente los de clasificación, en particular Árboles de decisión, Naive Bayes, regresión logística y Support Vector Classifier. La elección de los modelos de clasificación esta guiada por el saber que tan viable es obtener una reseña positiva dados ciertos N-gramas. Ya que el entrenamiento es la parte mas pesada de este proceso, también se ha decidido el guardar la data mediante los comandos de joblib.\n",
    "\n",
    "Cabe mencionar que en principio se realizarón comparaciones con respecto a los resultados obtenidos entre limitaciones a la vectorización eliminando todo aquel dato que tuviese baja representatividad y el dataset sin alteraciones. Los resultados para 1-gramas arrojaron las métricas que se muestran a continuación:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Datos obtenidos en el dataset sin restricciones    |      Datos obtenidos en el dataset con min_df=0.0005\n",
    "         Accuracy en test set: 0.753245910153207       |         Accuracy en test set: 0.7290963386133472\n",
    "                                                       |\n",
    "              precision    recall  f1-score   support  |                precision    recall  f1-score   support\n",
    "                                                       |\n",
    "    NEGATIVE       0.83      0.76      0.79      5135  |      NEGATIVE       0.81      0.73      0.77      5135\n",
    "     NEUTRAL       0.76      0.74      0.75      5135  |       NEUTRAL       0.74      0.69      0.72      5135\n",
    "    POSITIVE       0.69      0.76      0.73      5134  |      POSITIVE       0.65      0.76      0.70      5134\n",
    "                                                       |\n",
    "    accuracy                           0.75     15404  |      accuracy                           0.73     15404\n",
    "    macro avg      0.76      0.75      0.75     15404  |     macro avg       0.74      0.73      0.73     15404\n",
    "    weighted avg   0.76      0.75      0.75     15404  |  weighted avg       0.74      0.73      0.73     15404"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es posible observar, las métricas obtenidas al limitar la vectorización del dataset son levemente inferiores a las métricas obtenidas con el dataset sin restricciones. Por esta razón, en favor de buscar el resultado más adecuado, y dado un posible aumento en las diferencias de metricas a medida que se procede con los siguiente N-gramas, se ha decidido usar los datasets sin alteraciones, pese a los tiempos de ejecución más lentos.\n",
    "\n",
    "Se procede a cargar los modelos con \"joblib\" y a extraer las principales métricas de desempeño para medir cual de los modelos ha sido el mas confiable con el entrenamiento dado. Estas métricas ayudarán en la comparación de modelos para decidir cual de ellos es mejor para poder responder la pregunta planteada. Tanto para 2-gramas como 3-gramas, se sigue el mismo procedimiento descrito anteriormente. Cabe resaltar la importancia de la librería joblib, ya que el procesamiento del entrenamiento de los modelos es una tarea conocida por ser pesada computacionalmente hablando. Queda en el anexo todo el código descrito en esta explicación, mientras que en la sección de Experimento preliminar se presentan los principales resultados.\n",
    "\n",
    "## Pregunta 2\n",
    "\n",
    "Para la segunda pregunta, se siguen los mismos pasos del preprocesamiento en la pregunta anterior, añadiéndose la adición y edición de nuevas columnas que ayudarán en el trabajo de visualización de los datos. Se harán cambios de formato, eliminación de datos que no sean de interés para esta sección, se normalizarán datos y, principalmente, se cambiará el formato de muestra del rating, ya que para clustering se necesitara que este dato se exprese como valor entero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo que muestre parte del preprocesamiento adicional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definirán los valores X e Y que servirán para la formación de los grupos con los cuales los algoritmos de clustering trabajarán, y, usando X, se procede con Analisis de Componentes Principales, a modo de reducir tanto la dimensionalidad, como la complejidad de los datos, esto para que sea más fácil hallar patrones visibles en los clusters.\n",
    "\n",
    "Los métodos de clustering a utilizar son, en principio, K-Means en un rango de 1 a 10 clusters. Esto determinará cual sería la cantidad de clusters ideal para poder responder la pregunta, por lo que adicionalmente se contará con el método del codo para determinar esto.\n",
    "\n",
    "Para la validación, se contara con el uso de matrices de similitud, las cuales otorgarán una inspección visual sobre que método de clustering resulta mas efectivo a la hora de obtener clusters de los datos\n",
    "\n",
    "## Pregunta 3\n",
    "\n",
    "Para responder la tercera pregunta, se hará nuevamente uso de los métodos de clasificación, esta vez iniciando con el dataset original y con un preprocesamiento leve, basado en cambios de formatos como el aspecto mas importante a considerar.\n",
    "\n",
    "Primero, se hará una visualización sobre el comportamiento de reseñas por tiempo, mostrando la cantidad de reseñas obtenidas en un periodo de tiempo, esto por cada valor de rating. Luego, se procede con la vectorización y entrenamiento de modelos de clasificación, usando en este caso Árboles de decisión con distintos criterios, Dummy Classifier, Gausiana Naive Bayes, K-Neighbors y SVC. De los resultados generados por cada modelo se extraen sus métricas de desempeño, para obtener aquel algoritmo que se haya comportado mejor a la hora de realizar el entrenamiento, o bien, aquel que se haya desempeñado mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo de apoyo de la idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, para ver la exactitud de los métodos, se usarán matrices de confusión para obtener las métricas de desempeño de manera mas visual. Se realizará adicionalmente una validación cruzada entre Árboles de decisión y GridSearchCV, esto ya que la validación proporciona una visualización de la medida mas fiable del rendimiento de los modelos ejecutados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento preliminar\n",
    "## Pregunta 1\n",
    "\n",
    "Aqui se añaden los principales resultados obtenidos de la experimentación en esta pregunta. Se mostrarán las tablas con las métricas de desempeño obtenidas por cada N-grama del 1 al 3. Para simplificación de la muestra, P = precision, R = recall, F1 = F1-score y S = support. A su vez, los modelos se nombran como DTC = DecisionTreeClassifier, NB = Naive Bayes, LR = Regresión logistica y SVC = Support Vector Machine.\n",
    "\n",
    "                         1-gram                     2-grama                    3-grama\n",
    "          \n",
    "    Accuracy test set: 0.753245910153207  |      0.7294209296286679  |  \n",
    "  \n",
    "           > DTC  P     R     F1    S     |  P     R     F1    S     |  P     R     F1    S     \n",
    "\n",
    "        NEGATIVE  0.83  0.76  0.79  5135  |  0.89  0.61  0.72  5135  |  \n",
    "         NEUTRAL  0.76  0.74  0.75  5135  |  0.84  0.70  0.76  5135  |  \n",
    "        POSITIVE  0.69  0.76  0.73  5134  |  0.59  0.88  0.71  5134  |  \n",
    "\n",
    "        accuracy              0.75 15404  |              0.73 15404  |  \n",
    "       macro avg  0.76  0.75  0.75 15404  |  0.77  0.73  0.73 15404  |  \n",
    "    weighted avg  0.76  0.75  0.75 15404  |  0.77  0.73  0.73 15404  |  \n",
    "    \n",
    "    --------------------------------------+--------------------------+----------------------------\n",
    "    \n",
    "    Accuracy test set: 0.6999480654375487 |      0.7174759802648663\n",
    "    \n",
    "            > NB  P     R     F1    S     |  P     R     F1    S     |  P     R     F1    S   \n",
    "\n",
    "        NEGATIVE  0.80  0.71  0.75  5135  |  0.88  0.61  0.72  5135  |  \n",
    "         NEUTRAL  0.68  0.56  0.62  5135  |  0.80  0.66  0.72  5135  |  \n",
    "        POSITIVE  0.64  0.83  0.72  5134  |  0.59  0.88  0.71  5134  |  \n",
    "\n",
    "        accuracy              0.70 15404  |              0.72 15404  |  \n",
    "       macro avg  0.71  0.70  0.70 15404  |  0.76  0.72  0.72 15404  |  \n",
    "    weighted avg  0.71  0.70  0.70 15404  |  0.76  0.72  0.72 15404  |  \n",
    "    \n",
    "    --------------------------------------+--------------------------+----------------------------\n",
    "    \n",
    "    Accuracy test set: 0.7331212672033238 |       0.738314723448455  |  \n",
    "            \n",
    "            > LR  P     R     F1    S     |  P     R     F1    S     |  P     R     F1    S   \n",
    "\n",
    "        NEGATIVE  0.82  0.75  0.78  5135  |  0.90  0.63  0.74  5135  |  \n",
    "         NEUTRAL  0.75  0.61  0.67  5135  |  0.84  0.68  0.75  5135  |  \n",
    "        POSITIVE  0.66  0.84  0.74  5134  |  0.61  0.91  0.73  5134  |  \n",
    "\n",
    "        accuracy              0.73 15404  |              0.74 15404  |  \n",
    "       macro avg  0.74  0.73  0.73 15404  |  0.78  0.74  0.74 15404  |  \n",
    "    weighted avg  0.74  0.73  0.73 15404  |  0.78  0.74  0.74 15404  |  \n",
    "    \n",
    "    --------------------------------------+--------------------------+----------------------------\n",
    "     \n",
    "    Accuracy test set: 0.729940275253181  |      0.6929368995066216\n",
    "           > SVC  P     R     F1    S     |  P     R     F1    S     |  P     R     F1    S   \n",
    "\n",
    "        NEGATIVE  0.82  0.75  0.78  5135  |  0.77  0.65  0.71  5135  |  \n",
    "         NEUTRAL  0.82  0.58  0.68  5135  |  0.90  0.58  0.70  5135  |  \n",
    "        POSITIVE  0.63  0.86  0.73  5134  |  0.56  0.85  0.68  5134  |  \n",
    "\n",
    "        accuracy              0.73 15404  |              0.69 15404  |  \n",
    "       macro avg  0.75  0.73  0.73 15404  |  0.75  0.69  0.70 15404  |  \n",
    "    weighted avg  0.75  0.73  0.73 15404  |  0.75  0.69  0.70 15404  |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Analisis de los resultados previos + prueba de una critica random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anexo\n",
    "## Código Pregunta 1\n",
    "### Preprocesamiento del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"threads.csv\") # carga del dataset a usar como variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para convertir el rating a palabras\n",
    "def ratingTransform(rating):\n",
    "    if rating <= 2:\n",
    "        return \"NEGATIVE\"\n",
    "    elif rating <= 4:\n",
    "        return \"NEUTRAL\"\n",
    "    else:\n",
    "        return \"POSITIVE\"\n",
    "\n",
    "# creacion del grafico de pie de las reviews segun rating\n",
    "data[\"rating\"] = data[\"rating\"].apply(ratingTransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(review):\n",
    "\n",
    "    review = review.lower()\n",
    "    review = re.sub('[^a-z A-Z 0-9-]+', '', review)\n",
    "    review = \" \".join([word for word in review.split() if word not in stopwords.words('english')])\n",
    "\n",
    "    return review\n",
    "\n",
    "data['review_description'] = data['review_description'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(X,y):\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_resample, y_resample = ros.fit_resample(X, y)\n",
    "    return (X_resample, y_resample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-gram\n",
    "**Dataset sin limitaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(data[\"review_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "X_1gram = vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1gram, y1 = oversampling(X_1gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y1_test.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_1gram, y1, test_size=0.33, random_state=37,stratify=y1)\n",
    "joblib.dump(X1_train, 'modelos/X1_train.pkl')\n",
    "joblib.dump(X1_test, 'modelos/X1_test.pkl')\n",
    "joblib.dump(y1_train, 'modelos/y1_train.pkl')\n",
    "joblib.dump(y1_test, 'modelos/y1_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset con mindf = 0.0005**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=0.0005)\n",
    "vectors = vectorizer.fit_transform(data[\"review_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "X_11gram = vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_11gram, y11 = oversampling(X_11gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y11_test.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X11_train, X11_test, y11_train, y11_test = train_test_split(X_11gram, y11, test_size=0.33, random_state=37,stratify=y11)\n",
    "joblib.dump(X11_train, 'modelos/X11_train.pkl')\n",
    "joblib.dump(X11_test, 'modelos/X11_test.pkl')\n",
    "joblib.dump(y11_train, 'modelos/y11_train.pkl')\n",
    "joblib.dump(y11_test, 'modelos/y11_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar Modelos\n",
    "**Dataset sin limitaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = joblib.load('modelos/X1_train.pkl')\n",
    "y1_train = joblib.load('modelos/y1_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_DecisionTreeClassifier.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X1_train, y1_train) \n",
    "joblib.dump(clf, \"modelos/1-gram_trained_DecisionTreeClassifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_NV.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X1_train, y1_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_trained_NV.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_logistic_regesion.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X1_train, y1_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_logistic_regesion.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_svc.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X1_train, y1_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_trained_svc.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset con mindf = 0.0005**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X11_train = joblib.load('modelos/X11_train.pkl')\n",
    "y11_train = joblib.load('modelos/y11_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_DecisionTreeClassifier_md.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X11_train, y11_train) \n",
    "joblib.dump(clf, \"modelos/1-gram_trained_DecisionTreeClassifier_md.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_NV_md.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X11_train, y11_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_trained_NV_md.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_logistic_regesion_md.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X11_train, y11_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_logistic_regesion_md.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_svc_md.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X11_train, y11_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_trained_svc_md.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelos para evaluar\n",
    "**Dataset sin limitaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = joblib.load('modelos/X1_test.pkl')\n",
    "y1_test = joblib.load('modelos/y1_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.753245910153207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.83      0.76      0.79      5135\n",
      "     NEUTRAL       0.76      0.74      0.75      5135\n",
      "    POSITIVE       0.69      0.76      0.73      5134\n",
      "\n",
      "    accuracy                           0.75     15404\n",
      "   macro avg       0.76      0.75      0.75     15404\n",
      "weighted avg       0.76      0.75      0.75     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_DecisionTreeClassifier.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.6999480654375487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.80      0.71      0.75      5135\n",
      "     NEUTRAL       0.68      0.56      0.62      5135\n",
      "    POSITIVE       0.64      0.83      0.72      5134\n",
      "\n",
      "    accuracy                           0.70     15404\n",
      "   macro avg       0.71      0.70      0.70     15404\n",
      "weighted avg       0.71      0.70      0.70     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_NV.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7331212672033238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.82      0.75      0.78      5135\n",
      "     NEUTRAL       0.75      0.61      0.67      5135\n",
      "    POSITIVE       0.66      0.84      0.74      5134\n",
      "\n",
      "    accuracy                           0.73     15404\n",
      "   macro avg       0.74      0.73      0.73     15404\n",
      "weighted avg       0.74      0.73      0.73     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_logistic_regesion.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.729940275253181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.82      0.75      0.78      5135\n",
      "     NEUTRAL       0.82      0.58      0.68      5135\n",
      "    POSITIVE       0.63      0.86      0.73      5134\n",
      "\n",
      "    accuracy                           0.73     15404\n",
      "   macro avg       0.75      0.73      0.73     15404\n",
      "weighted avg       0.75      0.73      0.73     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_svc.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset con mindf = 0.0005**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X11_test = joblib.load('modelos/X11_test.pkl')\n",
    "y11_test = joblib.load('modelos/y11_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7290963386133472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.81      0.73      0.77      5135\n",
      "     NEUTRAL       0.74      0.69      0.72      5135\n",
      "    POSITIVE       0.65      0.76      0.70      5134\n",
      "\n",
      "    accuracy                           0.73     15404\n",
      "   macro avg       0.74      0.73      0.73     15404\n",
      "weighted avg       0.74      0.73      0.73     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_DecisionTreeClassifier_md.joblib\")\n",
    "y11_pred = clf.predict(X11_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y11_test, y11_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y11_test, y11_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.6627499350817969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.76      0.67      0.72      5135\n",
      "     NEUTRAL       0.67      0.45      0.54      5135\n",
      "    POSITIVE       0.60      0.86      0.70      5134\n",
      "\n",
      "    accuracy                           0.66     15404\n",
      "   macro avg       0.68      0.66      0.65     15404\n",
      "weighted avg       0.68      0.66      0.65     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_NV_md.joblib\")\n",
    "y11_pred = clf.predict(X11_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y11_test, y11_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y11_test, y11_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.6769021033497793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.77      0.70      0.73      5135\n",
      "     NEUTRAL       0.69      0.49      0.57      5135\n",
      "    POSITIVE       0.61      0.84      0.71      5134\n",
      "\n",
      "    accuracy                           0.68     15404\n",
      "   macro avg       0.69      0.68      0.67     15404\n",
      "weighted avg       0.69      0.68      0.67     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_logistic_regesion_md.joblib\")\n",
    "y11_pred = clf.predict(X11_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y11_test, y11_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y11_test, y11_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7174110620618022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.82      0.73      0.77      5135\n",
      "     NEUTRAL       0.80      0.55      0.65      5135\n",
      "    POSITIVE       0.61      0.87      0.72      5134\n",
      "\n",
      "    accuracy                           0.72     15404\n",
      "   macro avg       0.74      0.72      0.71     15404\n",
      "weighted avg       0.74      0.72      0.71     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_svc_md.joblib\")\n",
    "y11_pred = clf.predict(X11_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y11_test, y11_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y11_test, y11_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2,2))\n",
    "bigrams = cv.fit_transform(data['review_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = pd.DataFrame(bigrams.toarray(), columns=cv.get_feature_names_out())\n",
    "X_2gram = bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2gram, y2 = oversampling(X_2gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y2_test.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_2gram, y2, test_size=0.33, random_state=37,stratify=y2)\n",
    "joblib.dump(X2_train, 'modelos/X2_train.pkl')\n",
    "joblib.dump(X2_test, 'modelos/X2_test.pkl')\n",
    "joblib.dump(y2_train, 'modelos/y2_train.pkl')\n",
    "joblib.dump(y2_test, 'modelos/y2_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = joblib.load('modelos/X2_train.pkl')\n",
    "y2_train = joblib.load('modelos/y2_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_trained_DecisionTreeClassifier.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X2_train, y2_train) \n",
    "joblib.dump(clf, \"modelos/2-gram_trained_DecisionTreeClassifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_trained_NV.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X2_train, y2_train)\n",
    "joblib.dump(clf, \"modelos/2-gram_trained_NV.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_logistic_regesion.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X2_train, y2_train)\n",
    "joblib.dump(clf, \"modelos/2-gram_logistic_regesion.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_trained_svc.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X2_train, y2_train)\n",
    "joblib.dump(clf, \"modelos/2-gram_trained_svc.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelos para evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_test = joblib.load('modelos/X2_test.pkl')\n",
    "y2_test = joblib.load('modelos/y2_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7294209296286679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.89      0.61      0.72      5135\n",
      "     NEUTRAL       0.84      0.70      0.76      5135\n",
      "    POSITIVE       0.59      0.88      0.71      5134\n",
      "\n",
      "    accuracy                           0.73     15404\n",
      "   macro avg       0.77      0.73      0.73     15404\n",
      "weighted avg       0.77      0.73      0.73     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_trained_DecisionTreeClassifier.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7174759802648663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.88      0.61      0.72      5135\n",
      "     NEUTRAL       0.80      0.66      0.72      5135\n",
      "    POSITIVE       0.59      0.88      0.71      5134\n",
      "\n",
      "    accuracy                           0.72     15404\n",
      "   macro avg       0.76      0.72      0.72     15404\n",
      "weighted avg       0.76      0.72      0.72     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_trained_NV.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.738314723448455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.90      0.63      0.74      5135\n",
      "     NEUTRAL       0.84      0.68      0.75      5135\n",
      "    POSITIVE       0.61      0.91      0.73      5134\n",
      "\n",
      "    accuracy                           0.74     15404\n",
      "   macro avg       0.78      0.74      0.74     15404\n",
      "weighted avg       0.78      0.74      0.74     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_logistic_regesion.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.6929368995066216\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.77      0.65      0.71      5135\n",
      "     NEUTRAL       0.90      0.58      0.70      5135\n",
      "    POSITIVE       0.56      0.85      0.68      5134\n",
      "\n",
      "    accuracy                           0.69     15404\n",
      "   macro avg       0.75      0.69      0.70     15404\n",
      "weighted avg       0.75      0.69      0.70     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_trained_svc.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv1 = CountVectorizer(ngram_range=(3,3),min_df=0.00005)\n",
    "cv1 = CountVectorizer(ngram_range=(3,3))\n",
    "trigrams = cv1.fit_transform(data['review_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = pd.DataFrame(trigrams.toarray(), columns=cv1.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3gram = trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\felip\\OneDrive\\Escritorio\\Universidad\\8vo_Semestre\\Mineria\\App-Reviewer\\pregunta1.ipynb Cell 74\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Escritorio/Universidad/8vo_Semestre/Mineria/App-Reviewer/pregunta1.ipynb#Y133sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_3gram, y3 \u001b[39m=\u001b[39m oversampling(X_3gram, Y)\n",
      "\u001b[1;32mc:\\Users\\felip\\OneDrive\\Escritorio\\Universidad\\8vo_Semestre\\Mineria\\App-Reviewer\\pregunta1.ipynb Cell 74\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Escritorio/Universidad/8vo_Semestre/Mineria/App-Reviewer/pregunta1.ipynb#Y133sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moversampling\u001b[39m(X,y):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Escritorio/Universidad/8vo_Semestre/Mineria/App-Reviewer/pregunta1.ipynb#Y133sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     ros \u001b[39m=\u001b[39m RandomOverSampler(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Escritorio/Universidad/8vo_Semestre/Mineria/App-Reviewer/pregunta1.ipynb#Y133sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     X_resample, y_resample \u001b[39m=\u001b[39m ros\u001b[39m.\u001b[39;49mfit_resample(X, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Escritorio/Universidad/8vo_Semestre/Mineria/App-Reviewer/pregunta1.ipynb#Y133sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (X_resample, y_resample)\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_resample(X, y)\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:118\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    112\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_resample(X, y)\n\u001b[0;32m    114\u001b[0m y_ \u001b[39m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m     label_binarize(output[\u001b[39m1\u001b[39m], classes\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39munique(y)) \u001b[39mif\u001b[39;00m binarize_y \u001b[39melse\u001b[39;00m output[\u001b[39m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m )\n\u001b[1;32m--> 118\u001b[0m X_, y_ \u001b[39m=\u001b[39m arrays_transformer\u001b[39m.\u001b[39;49mtransform(output[\u001b[39m0\u001b[39;49m], y_)\n\u001b[0;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m (X_, y_) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(output) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m (X_, y_, output[\u001b[39m2\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_validation.py:39\u001b[0m, in \u001b[0;36mArraysTransformer.transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m---> 39\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transfrom_one(X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx_props)\n\u001b[0;32m     40\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfrom_one(y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_props)\n\u001b[0;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_props[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdataframe\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_props[\n\u001b[0;32m     42\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     43\u001b[0m     ]\u001b[39m.\u001b[39mlower() \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdataframe\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m     44\u001b[0m         \u001b[39m# We lost the y.index during resampling. We can safely use X.index to align\u001b[39;00m\n\u001b[0;32m     45\u001b[0m         \u001b[39m# them.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_validation.py:65\u001b[0m, in \u001b[0;36mArraysTransformer._transfrom_one\u001b[1;34m(self, array, props)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     ret \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(array, columns\u001b[39m=\u001b[39mprops[\u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m---> 65\u001b[0m     ret \u001b[39m=\u001b[39m ret\u001b[39m.\u001b[39;49mastype(props[\u001b[39m\"\u001b[39;49m\u001b[39mdtypes\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     66\u001b[0m \u001b[39melif\u001b[39;00m type_ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     67\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6226\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6224\u001b[0m             res_col \u001b[39m=\u001b[39m col\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m copy \u001b[39melse\u001b[39;00m col\n\u001b[0;32m   6225\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 6226\u001b[0m             res_col \u001b[39m=\u001b[39m col\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mcdt, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   6227\u001b[0m         results\u001b[39m.\u001b[39mappend(res_col)\n\u001b[0;32m   6229\u001b[0m \u001b[39melif\u001b[39;00m is_extension_array_dtype(dtype) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   6230\u001b[0m     \u001b[39m# GH 18099/22869: columnwise conversion to extension dtype\u001b[39;00m\n\u001b[0;32m   6231\u001b[0m     \u001b[39m# GH 24704: use iloc to handle duplicate column names\u001b[39;00m\n\u001b[0;32m   6232\u001b[0m     \u001b[39m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6233\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m   6234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m   6235\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m   6236\u001b[0m     ]\n\u001b[0;32m   6238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6239\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6240\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   6241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6243\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m--> 448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    524\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m--> 526\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    528\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    529\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 299\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    300\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    301\u001b[0m     \u001b[39m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:222\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m is_dtype_equal(values\u001b[39m.\u001b[39mdtype, dtype):\n\u001b[0;32m    221\u001b[0m     \u001b[39mif\u001b[39;00m copy:\n\u001b[1;32m--> 222\u001b[0m         \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    223\u001b[0m     \u001b[39mreturn\u001b[39;00m values\n\u001b[0;32m    225\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(values, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m    226\u001b[0m     \u001b[39m# i.e. ExtensionArray\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_3gram, y3 = oversampling(X_3gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y3_test.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X_3gram, y3, test_size=0.33, random_state=37,stratify=y3)\n",
    "joblib.dump(X3_train, 'modelos/X3_train.pkl')\n",
    "joblib.dump(X3_test, 'modelos/X3_test.pkl')\n",
    "joblib.dump(y3_train, 'modelos/y3_train.pkl')\n",
    "joblib.dump(y3_test, 'modelos/y3_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train = joblib.load('modelos/X3_train.pkl')\n",
    "y3_train = joblib.load('modelos/y3_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/3-gram_trained_DecisionTreeClassifier.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X3_train, y3_train) \n",
    "joblib.dump(clf, \"modelos/3-gram_trained_DecisionTreeClassifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/3-gram_trained_NV.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X3_train, y3_train)\n",
    "joblib.dump(clf, \"modelos/3-gram_trained_NV.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/3-gram_logistic_regesion.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X3_train, y3_train)\n",
    "joblib.dump(clf, \"modelos/3-gram_logistic_regesion.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/3-gram_trained_svc.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X3_train, y3_train)\n",
    "joblib.dump(clf, \"modelos/3-gram_trained_svc.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelos para evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\felip\\OneDrive\\Escritorio\\Universidad\\8vo_Semestre\\Mineria\\App-Reviewer\\pregunta1.ipynb Cell 82\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Escritorio/Universidad/8vo_Semestre/Mineria/App-Reviewer/pregunta1.ipynb#Y144sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X3_test \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mmodelos/X3_test.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/felip/OneDrive/Escritorio/Universidad/8vo_Semestre/Mineria/App-Reviewer/pregunta1.ipynb#Y144sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y3_test \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mmodelos/y3_test.pkl\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m                 \u001b[39mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 658\u001b[0m             obj \u001b[39m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[0;32m    659\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m    578\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[0;32m    579\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[0;32m    583\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39;49m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:415\u001b[0m, in \u001b[0;36mNumpyUnpickler.load_build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(array_wrapper, NDArrayWrapper):\n\u001b[0;32m    414\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompat_mode \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 415\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack\u001b[39m.\u001b[39mappend(array_wrapper\u001b[39m.\u001b[39;49mread(\u001b[39mself\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:252\u001b[0m, in \u001b[0;36mNumpyArrayWrapper.read\u001b[1;34m(self, unpickler)\u001b[0m\n\u001b[0;32m    250\u001b[0m     array \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_mmap(unpickler)\n\u001b[0;32m    251\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 252\u001b[0m     array \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(unpickler)\n\u001b[0;32m    254\u001b[0m \u001b[39m# Manage array subclass case\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mhasattr\u001b[39m(array, \u001b[39m'\u001b[39m\u001b[39m__array_prepare__\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubclass \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (unpickler\u001b[39m.\u001b[39mnp\u001b[39m.\u001b[39mndarray,\n\u001b[0;32m    257\u001b[0m                           unpickler\u001b[39m.\u001b[39mnp\u001b[39m.\u001b[39mmemmap)):\n\u001b[0;32m    258\u001b[0m     \u001b[39m# We need to reconstruct another subclass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:177\u001b[0m, in \u001b[0;36mNumpyArrayWrapper.read_array\u001b[1;34m(self, unpickler)\u001b[0m\n\u001b[0;32m    175\u001b[0m read_count \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(max_read_count, count \u001b[39m-\u001b[39m i)\n\u001b[0;32m    176\u001b[0m read_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(read_count \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mitemsize)\n\u001b[1;32m--> 177\u001b[0m data \u001b[39m=\u001b[39m _read_bytes(unpickler\u001b[39m.\u001b[39;49mfile_handle,\n\u001b[0;32m    178\u001b[0m                    read_size, \u001b[39m\"\u001b[39;49m\u001b[39marray data\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    179\u001b[0m array[i:i \u001b[39m+\u001b[39m read_count] \u001b[39m=\u001b[39m \\\n\u001b[0;32m    180\u001b[0m     unpickler\u001b[39m.\u001b[39mnp\u001b[39m.\u001b[39mfrombuffer(data, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype,\n\u001b[0;32m    181\u001b[0m                             count\u001b[39m=\u001b[39mread_count)\n\u001b[0;32m    182\u001b[0m \u001b[39mdel\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\felip\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle_utils.py:243\u001b[0m, in \u001b[0;36m_read_bytes\u001b[1;34m(fp, size, error_template)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[39m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[39m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[39m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 243\u001b[0m         r \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39mread(size \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(data))\n\u001b[0;32m    244\u001b[0m         data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m r\n\u001b[0;32m    245\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(r) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m==\u001b[39m size:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X3_test = joblib.load('modelos/X3_test.pkl')\n",
    "y3_test = joblib.load('modelos/y3_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.5235003895092184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.85      0.26      0.40      5135\n",
      "     NEUTRAL       0.81      0.37      0.50      5135\n",
      "    POSITIVE       0.42      0.94      0.58      5134\n",
      "\n",
      "    accuracy                           0.52     15404\n",
      "   macro avg       0.69      0.52      0.50     15404\n",
      "weighted avg       0.69      0.52      0.50     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_trained_DecisionTreeClassifier.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.508828875616723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.80      0.27      0.41      5135\n",
      "     NEUTRAL       0.76      0.30      0.43      5135\n",
      "    POSITIVE       0.42      0.95      0.58      5134\n",
      "\n",
      "    accuracy                           0.51     15404\n",
      "   macro avg       0.66      0.51      0.47     15404\n",
      "weighted avg       0.66      0.51      0.47     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_trained_NV.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.5246689171643729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.83      0.29      0.43      5135\n",
      "     NEUTRAL       0.77      0.35      0.48      5135\n",
      "    POSITIVE       0.43      0.94      0.59      5134\n",
      "\n",
      "    accuracy                           0.52     15404\n",
      "   macro avg       0.68      0.52      0.50     15404\n",
      "weighted avg       0.68      0.52      0.50     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_logistic_regesion.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.5309010646585303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.70      0.36      0.47      5135\n",
      "     NEUTRAL       0.86      0.35      0.50      5135\n",
      "    POSITIVE       0.42      0.89      0.57      5134\n",
      "\n",
      "    accuracy                           0.53     15404\n",
      "   macro avg       0.66      0.53      0.51     15404\n",
      "weighted avg       0.66      0.53      0.51     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_trained_svc.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
