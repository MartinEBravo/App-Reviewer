{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Librerías\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import seaborn as sns # plotting\n",
    "import string # string manipulation\n",
    "import re # regular expressions\n",
    "import nltk # text manipulation\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from tqdm import trange # progress bar\n",
    "from nltk import tokenize # text manipulation\n",
    "from nltk.corpus import stopwords # text manipulation\n",
    "from nltk.stem import WordNetLemmatizer # text manipulation\n",
    "from nltk.probability import FreqDist # text manipulation\n",
    "from collections import Counter # text manipulation\n",
    "from sklearn.feature_extraction.text import CountVectorizer # text manipulation\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator # wordcloud generator\n",
    "from IPython.display import display # image display\n",
    "from PIL import Image\n",
    "\n",
    "#hito 2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "import joblib # guardar modelos\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"threads.csv\") # carga del dataset a usar como variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para convertir el rating a palabras\n",
    "def ratingTransform(rating):\n",
    "    if rating <= 2:\n",
    "        return \"NEGATIVE\"\n",
    "    elif rating <= 4:\n",
    "        return \"NEUTRAL\"\n",
    "    else:\n",
    "        return \"POSITIVE\"\n",
    "\n",
    "# creacion del grafico de pie de las reviews segun rating\n",
    "data[\"rating\"] = data[\"rating\"].apply(ratingTransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(review):\n",
    "\n",
    "    review = review.lower()\n",
    "    review = re.sub('[^a-z A-Z 0-9-]+', '', review)\n",
    "    review = \" \".join([word for word in review.split() if word not in stopwords.words('english')])\n",
    "\n",
    "    return review\n",
    "\n",
    "data['review_description'] = data['review_description'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsampling(X, Y):\n",
    "    X['evaluacion'] = Y\n",
    "\n",
    "    clase_mayoritaria_1 = X[X['evaluacion'] == \"POSITIVE\"]\n",
    "    clase_mayoritaria_2 = X[X['evaluacion'] == \"NEGATIVE\"]\n",
    "    clase_minoritaria = X[X['evaluacion'] == \"NEUTRAL\"]\n",
    "\n",
    "    # Determinar el número de muestras de la clase minoritaria\n",
    "    num_muestras_minoritaria = len(clase_minoritaria)\n",
    "    # Realizar submuestreo de las clases mayoritarias\n",
    "    clase_mayoritaria_1_resample = clase_mayoritaria_1.sample(n=num_muestras_minoritaria, random_state=42)\n",
    "    clase_mayoritaria_2_resample = clase_mayoritaria_2.sample(n=num_muestras_minoritaria, random_state=42)\n",
    "\n",
    "    # Concatenar las clases remuestreadas con la clase minoritaria\n",
    "    df_resample = pd.concat([clase_mayoritaria_1_resample, clase_mayoritaria_2_resample, clase_minoritaria], axis=0)\n",
    "\n",
    "    # Separar de nuevo las características y las etiquetas\n",
    "    X_resample = df_resample.drop('evaluacion', axis=1)\n",
    "    y_resample = df_resample['evaluacion']\n",
    "    return (X_resample, y_resample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(data[\"review_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "X_1gram = vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1gram, y1 = subsampling(X_1gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y1_test.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_1gram, y1, test_size=0.33, random_state=37,stratify=y1)\n",
    "joblib.dump(X1_train, 'modelos/X1_train.pkl')\n",
    "joblib.dump(X1_test, 'modelos/X1_test.pkl')\n",
    "joblib.dump(y1_train, 'modelos/y1_train.pkl')\n",
    "joblib.dump(y1_test, 'modelos/y1_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = joblib.load('modelos/X1_train.pkl')\n",
    "y1_train = joblib.load('modelos/y1_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_DecisionTreeClassifier.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X1_train, y1_train) \n",
    "joblib.dump(clf, \"modelos/1-gram_trained_DecisionTreeClassifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_NV.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X1_train, y1_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_trained_NV.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_logistic_regesion.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X1_train, y1_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_logistic_regesion.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X1_train, y1_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_trained_svc.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelos para evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = joblib.load('modelos/X1_test.pkl')\n",
    "y1_test = joblib.load('modelos/y1_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.5784092878184024\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.65      0.60      0.62      1924\n",
      "     NEUTRAL       0.53      0.40      0.45      1924\n",
      "    POSITIVE       0.56      0.74      0.64      1923\n",
      "\n",
      "    accuracy                           0.58      5771\n",
      "   macro avg       0.58      0.58      0.57      5771\n",
      "weighted avg       0.58      0.58      0.57      5771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_DecisionTreeClassifier.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.6575983365101369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.76      0.66      0.71      1924\n",
      "     NEUTRAL       0.61      0.55      0.58      1924\n",
      "    POSITIVE       0.62      0.76      0.69      1923\n",
      "\n",
      "    accuracy                           0.66      5771\n",
      "   macro avg       0.66      0.66      0.66      5771\n",
      "weighted avg       0.66      0.66      0.66      5771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_NV.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.6510136891353319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.74      0.67      0.71      1924\n",
      "     NEUTRAL       0.63      0.45      0.53      1924\n",
      "    POSITIVE       0.60      0.83      0.70      1923\n",
      "\n",
      "    accuracy                           0.65      5771\n",
      "   macro avg       0.66      0.65      0.64      5771\n",
      "weighted avg       0.66      0.65      0.64      5771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_logistic_regesion.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'modelos/1-gram_trained_svc.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dani\\OneDrive - Universidad de Chile\\Universidad\\06) sexto semestre\\Mineria\\App-Reviewer\\pregunta1.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Dani/OneDrive%20-%20Universidad%20de%20Chile/Universidad/06%29%20sexto%20semestre/Mineria/App-Reviewer/pregunta1.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m clf \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mmodelos/1-gram_trained_svc.joblib\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dani/OneDrive%20-%20Universidad%20de%20Chile/Universidad/06%29%20sexto%20semestre/Mineria/App-Reviewer/pregunta1.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y1_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X1_test)   \u001b[39m## Predecimos con nuevos datos (los de test X_test)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dani/OneDrive%20-%20Universidad%20de%20Chile/Universidad/06%29%20sexto%20semestre/Mineria/App-Reviewer/pregunta1.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy en test set:\u001b[39m\u001b[39m\"\u001b[39m, accuracy_score(y1_test, y1_pred))   \u001b[39m## Evaluamos la predicción comparando y_test con y1_pred\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dani\\anaconda3\\envs\\mineria\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[39mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'modelos/1-gram_trained_svc.joblib'"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_svc.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2,2))\n",
    "bigrams = cv.fit_transform(data['review_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = pd.DataFrame(bigrams.toarray(), columns=cv.get_feature_names_out())\n",
    "X_2gram = bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2gram, y2 = subsampling(X_2gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y2_test.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_2gram, y2, test_size=0.33, random_state=37,stratify=y2)\n",
    "joblib.dump(X2_train, 'modelos/X2_train.pkl')\n",
    "joblib.dump(X2_test, 'modelos/X2_test.pkl')\n",
    "joblib.dump(y2_train, 'modelos/y2_train.pkl')\n",
    "joblib.dump(y2_test, 'modelos/y2_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = joblib.load('modelos/X2_train.pkl')\n",
    "y2_train = joblib.load('modelos/y2_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_trained_DecisionTreeClassifier.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X2_train, y2_train) \n",
    "joblib.dump(clf, \"modelos/2-gram_trained_DecisionTreeClassifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_trained_NV.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X2_train, y2_train)\n",
    "joblib.dump(clf, \"modelos/2-gram_trained_NV.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_logistic_regesion.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X2_train, y2_train)\n",
    "joblib.dump(clf, \"modelos/2-gram_logistic_regesion.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X2_train, y2_train)\n",
    "joblib.dump(clf, \"modelos/2-gram_trained_svc.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelos para evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_test = joblib.load('modelos/X2_test.pkl')\n",
    "y2_test = joblib.load('modelos/y2_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.5146421763992376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.66      0.42      0.52      1924\n",
      "     NEUTRAL       0.57      0.23      0.33      1924\n",
      "    POSITIVE       0.45      0.89      0.60      1923\n",
      "\n",
      "    accuracy                           0.51      5771\n",
      "   macro avg       0.56      0.51      0.48      5771\n",
      "weighted avg       0.56      0.51      0.48      5771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_trained_DecisionTreeClassifier.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.5803153699532143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.73      0.49      0.59      1924\n",
      "     NEUTRAL       0.61      0.41      0.49      1924\n",
      "    POSITIVE       0.51      0.84      0.63      1923\n",
      "\n",
      "    accuracy                           0.58      5771\n",
      "   macro avg       0.62      0.58      0.57      5771\n",
      "weighted avg       0.62      0.58      0.57      5771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_trained_NV.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.5687055969502686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.74      0.46      0.57      1924\n",
      "     NEUTRAL       0.63      0.35      0.45      1924\n",
      "    POSITIVE       0.49      0.90      0.63      1923\n",
      "\n",
      "    accuracy                           0.57      5771\n",
      "   macro avg       0.62      0.57      0.55      5771\n",
      "weighted avg       0.62      0.57      0.55      5771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_logistic_regesion.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_trained_svc.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = CountVectorizer(ngram_range=(3,3))\n",
    "trigrams = cv1.fit_transform(data['review_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = pd.DataFrame(trigrams.toarray(), columns=cv1.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3gram = trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3gram, y3 = subsampling(X_3gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y3_test.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X_3gram, y3, test_size=0.33, random_state=37,stratify=y3)\n",
    "joblib.dump(X3_train, 'modelos/X3_train.pkl')\n",
    "joblib.dump(X3_test, 'modelos/X3_test.pkl')\n",
    "joblib.dump(y3_train, 'modelos/y3_train.pkl')\n",
    "joblib.dump(y3_test, 'modelos/y3_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train = joblib.load('modelos/X3_train.pkl')\n",
    "y3_train = joblib.load('modelos/y3_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/3-gram_trained_DecisionTreeClassifier.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X3_train, y3_train) \n",
    "joblib.dump(clf, \"modelos/3-gram_trained_DecisionTreeClassifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/3-gram_trained_NV.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X3_train, y3_train)\n",
    "joblib.dump(clf, \"modelos/3-gram_trained_NV.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/3-gram_logistic_regesion.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X3_train, y3_train)\n",
    "joblib.dump(clf, \"modelos/3-gram_logistic_regesion.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X3_train, y3_train)\n",
    "joblib.dump(clf, \"modelos/3-gram_trained_svc.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelos para evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_test = joblib.load('modelos/X3_test.pkl')\n",
    "y3_test = joblib.load('modelos/y3_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.3990642869520014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.73      0.14      0.23      1924\n",
      "     NEUTRAL       0.59      0.09      0.16      1924\n",
      "    POSITIVE       0.36      0.97      0.53      1923\n",
      "\n",
      "    accuracy                           0.40      5771\n",
      "   macro avg       0.56      0.40      0.31      5771\n",
      "weighted avg       0.56      0.40      0.31      5771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_trained_DecisionTreeClassifier.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.4049558135505112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.71      0.16      0.27      1924\n",
      "     NEUTRAL       0.59      0.09      0.16      1924\n",
      "    POSITIVE       0.37      0.96      0.53      1923\n",
      "\n",
      "    accuracy                           0.40      5771\n",
      "   macro avg       0.55      0.41      0.32      5771\n",
      "weighted avg       0.55      0.40      0.32      5771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_trained_NV.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.41032749956679954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.72      0.16      0.27      1924\n",
      "     NEUTRAL       0.63      0.10      0.17      1924\n",
      "    POSITIVE       0.37      0.97      0.54      1923\n",
      "\n",
      "    accuracy                           0.41      5771\n",
      "   macro avg       0.57      0.41      0.32      5771\n",
      "weighted avg       0.57      0.41      0.32      5771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_logistic_regesion.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_trained_svc.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mineria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
