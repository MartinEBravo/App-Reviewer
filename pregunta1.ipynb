{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\felip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\felip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Librerías\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import seaborn as sns # plotting\n",
    "import string # string manipulation\n",
    "import re # regular expressions\n",
    "import nltk # text manipulation\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from tqdm import trange # progress bar\n",
    "from nltk import tokenize # text manipulation\n",
    "from nltk.corpus import stopwords # text manipulation\n",
    "from nltk.stem import WordNetLemmatizer # text manipulation\n",
    "from nltk.probability import FreqDist # text manipulation\n",
    "from collections import Counter # text manipulation\n",
    "from sklearn.feature_extraction.text import CountVectorizer # text manipulation\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator # wordcloud generator\n",
    "from IPython.display import display # image display\n",
    "from PIL import Image\n",
    "\n",
    "#hito 2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "import joblib # guardar modelos\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como propuesta experimental, en este proyecto se hará uso de los métodos de clustering para la pregunta 2 y clasificación para la 1 y 3. Dado que clasificación es un método supervisado, adicionalmente se realizarán pruebas para obtener métricas de desempeño para escoger el mejor método de clasificación, mientras que, para el caso de clustering, al ser no supervisado, se deberán usar métodos para validar los clusters generados.\n",
    "\n",
    "Para responder la primera pregunta, se ha realizado un preprocesamiento que consta de, en primer lugar, la conversión del rating a palabras, a modo de limitar las categorías de originalmente 5 a 3. En segundo lugar, se hace la limpieza del dataset de aquellas palabras poco útiles para nuestro propósito, por lo que se filtran números, stopwords y se actualiza todo el texto del dataset de reseñas a minúsculas. Dado que, aún con la conversión de ratings existen categorías que quedan subrepresentadas en comparación a otras, se hace un oversampling basado en el rating de las reseñas para obtener un balanceo de datos para que los modelos generados sean mas correctos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para convertir el rating a palabras\n",
    "def ratingTransform(rating):\n",
    "    if rating <= 2:\n",
    "        return \"NEGATIVE\"\n",
    "    elif rating <= 4:\n",
    "        return \"NEUTRAL\"\n",
    "    else:\n",
    "        return \"POSITIVE\"\n",
    "\n",
    "# funcion para realizar la limpieza del texto en el dataset\n",
    "def clean(review):\n",
    "    review = review.lower()\n",
    "    review = re.sub('[^a-z A-Z 0-9-]+', '', review)\n",
    "    review = \" \".join([word for word in review.split() if word not in stopwords.words('english')])\n",
    "    return review\n",
    "\n",
    "# funcion para hacer oversampling de los datos que se encuentran desbalanceados\n",
    "def oversampling(X,y):\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_resample, y_resample = ros.fit_resample(X, y)\n",
    "    return (X_resample, y_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prosiguiendo con los N-gramas, se verá lo que ocurre con los 1-gramas. Primero, se procede con la vectorización, ya que se quiere convertir el texto a una forma que los algoritmos de aprendizaje que se usarán posteriormente puedan entender y procesar. En este caso, dado que en el preprocesamiento se estableció la necesidad de hacer oversampling a los datos, la vectorización será útil para luego poder hacer dicho oversampling. Finalmente, se realiza la división de los datos entre datos de prueba (con el 33% de los datos destinado para eso) y datos de entrenamiento. Adicionalmente, se usarán funciones extras otorgadas por la librería “joblib”, la cual será de utilidad para guardar los datos procesados, para no tener necesidad de ejecutar todo desde el principio, y asi conservar el entrenamiento. Esto es de especial importancia por lo que se mencionara a continuación.\n",
    "\n",
    "Luego de almacenar la data útil para los algoritmos, se procede con el entrenamiento de los modelos. Para estos, se usarán principalmente los de clasificación, en particular Árboles de decisión, Naive Bayes, regresión logística y Support Vector Classifier. La elección de los modelos de clasificación esta guiada por el saber que tan viable es obtener una reseña positiva dados ciertos N-gramas. Ya que el entrenamiento es la parte mas pesada de este proceso, también se ha decidido el guardar la data mediante los comandos de joblib.\n",
    "\n",
    "Cabe mencionar que en principio se realizarón comparaciones con respecto a los resultados obtenidos entre limitaciones a la vectorización eliminando todo aquel dato que tuviese baja representatividad y el dataset sin alteraciones. Los resultados para 1-gramas arrojaron las métricas que se muestran a continuación:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar la data para 1-gramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es posible observar, las métricas obtenidas al limitar la vectorización del dataset son comparablemente inferiores a las métricas obtenidas con el dataset sin restricciones. Por esta razón, en favor de buscar el resultado más adecuado, se ha decidido usar los datasets sin alteraciones, pese a los tiempos de ejecución más lentos.\n",
    "\n",
    "Se procede a cargar los modelos con \"joblib\" y a extraer las principales métricas de desempeño para medir cual de los modelos ha sido el mas confiable con el entrenamiento dado. Estas métricas ayudarán en la comparación de modelos para decidir cual de ellos es mejor para poder responder la pregunta planteada. Tanto para 2-gramas como 3-gramas, se sigue el mismo procedimiento descrito anteriormente. Cabe resaltar la importancia de la librería joblib, ya que el procesamiento del entrenamiento de los modelos es una tarea conocida por ser pesada computacionalmente hablando. Queda en el anexo todo el código descrito en esta explicación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy en test set: 0.753245910153207\n",
    "              \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "    NEGATIVE       0.83      0.76      0.79      5135\n",
    "     NEUTRAL       0.76      0.74      0.75      5135\n",
    "    POSITIVE       0.69      0.76      0.73      5134\n",
    "\n",
    "    accuracy                           0.75     15404\n",
    "   \n",
    "   macro avg       0.76      0.75      0.75     15404\n",
    "weighted avg       0.76      0.75      0.75     15404\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código Pregunta 1\n",
    "### Preprocesamiento del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"threads.csv\") # carga del dataset a usar como variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para convertir el rating a palabras\n",
    "def ratingTransform(rating):\n",
    "    if rating <= 2:\n",
    "        return \"NEGATIVE\"\n",
    "    elif rating <= 4:\n",
    "        return \"NEUTRAL\"\n",
    "    else:\n",
    "        return \"POSITIVE\"\n",
    "\n",
    "# creacion del grafico de pie de las reviews segun rating\n",
    "data[\"rating\"] = data[\"rating\"].apply(ratingTransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(review):\n",
    "\n",
    "    review = review.lower()\n",
    "    review = re.sub('[^a-z A-Z 0-9-]+', '', review)\n",
    "    review = \" \".join([word for word in review.split() if word not in stopwords.words('english')])\n",
    "\n",
    "    return review\n",
    "\n",
    "data['review_description'] = data['review_description'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(X,y):\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_resample, y_resample = ros.fit_resample(X, y)\n",
    "    return (X_resample, y_resample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-gram\n",
    "**Dataset sin limitaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(data[\"review_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "X_1gram = vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1gram, y1 = oversampling(X_1gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y1_test.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_1gram, y1, test_size=0.33, random_state=37,stratify=y1)\n",
    "joblib.dump(X1_train, 'modelos/X1_train.pkl')\n",
    "joblib.dump(X1_test, 'modelos/X1_test.pkl')\n",
    "joblib.dump(y1_train, 'modelos/y1_train.pkl')\n",
    "joblib.dump(y1_test, 'modelos/y1_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset con mindf = 0.0005**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=0.0005)\n",
    "vectors = vectorizer.fit_transform(data[\"review_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "X_11gram = vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_11gram, y11 = oversampling(X_11gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y11_test.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X11_train, X11_test, y11_train, y11_test = train_test_split(X_11gram, y11, test_size=0.33, random_state=37,stratify=y11)\n",
    "joblib.dump(X11_train, 'modelos/X11_train.pkl')\n",
    "joblib.dump(X11_test, 'modelos/X11_test.pkl')\n",
    "joblib.dump(y11_train, 'modelos/y11_train.pkl')\n",
    "joblib.dump(y11_test, 'modelos/y11_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar Modelos\n",
    "**Dataset sin limitaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = joblib.load('modelos/X1_train.pkl')\n",
    "y1_train = joblib.load('modelos/y1_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_DecisionTreeClassifier.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X1_train, y1_train) \n",
    "joblib.dump(clf, \"modelos/1-gram_trained_DecisionTreeClassifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_NV.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X1_train, y1_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_trained_NV.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_logistic_regesion.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X1_train, y1_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_logistic_regesion.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_svc.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X1_train, y1_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_trained_svc.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset con mindf = 0.0005**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X11_train = joblib.load('modelos/X11_train.pkl')\n",
    "y11_train = joblib.load('modelos/y11_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_DecisionTreeClassifier_md.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X11_train, y11_train) \n",
    "joblib.dump(clf, \"modelos/1-gram_trained_DecisionTreeClassifier_md.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_NV_md.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X11_train, y11_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_trained_NV_md.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_logistic_regesion_md.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X11_train, y11_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_logistic_regesion_md.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_svc_md.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X11_train, y11_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_trained_svc_md.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelos para evaluar\n",
    "**Dataset sin limitaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = joblib.load('modelos/X1_test.pkl')\n",
    "y1_test = joblib.load('modelos/y1_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.753245910153207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.83      0.76      0.79      5135\n",
      "     NEUTRAL       0.76      0.74      0.75      5135\n",
      "    POSITIVE       0.69      0.76      0.73      5134\n",
      "\n",
      "    accuracy                           0.75     15404\n",
      "   macro avg       0.76      0.75      0.75     15404\n",
      "weighted avg       0.76      0.75      0.75     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_DecisionTreeClassifier.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.6999480654375487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.80      0.71      0.75      5135\n",
      "     NEUTRAL       0.68      0.56      0.62      5135\n",
      "    POSITIVE       0.64      0.83      0.72      5134\n",
      "\n",
      "    accuracy                           0.70     15404\n",
      "   macro avg       0.71      0.70      0.70     15404\n",
      "weighted avg       0.71      0.70      0.70     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_NV.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7331212672033238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.82      0.75      0.78      5135\n",
      "     NEUTRAL       0.75      0.61      0.67      5135\n",
      "    POSITIVE       0.66      0.84      0.74      5134\n",
      "\n",
      "    accuracy                           0.73     15404\n",
      "   macro avg       0.74      0.73      0.73     15404\n",
      "weighted avg       0.74      0.73      0.73     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_logistic_regesion.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.729940275253181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.82      0.75      0.78      5135\n",
      "     NEUTRAL       0.82      0.58      0.68      5135\n",
      "    POSITIVE       0.63      0.86      0.73      5134\n",
      "\n",
      "    accuracy                           0.73     15404\n",
      "   macro avg       0.75      0.73      0.73     15404\n",
      "weighted avg       0.75      0.73      0.73     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_svc.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset con mindf = 0.0005**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X11_test = joblib.load('modelos/X11_test.pkl')\n",
    "y11_test = joblib.load('modelos/y11_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7290963386133472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.81      0.73      0.77      5135\n",
      "     NEUTRAL       0.74      0.69      0.72      5135\n",
      "    POSITIVE       0.65      0.76      0.70      5134\n",
      "\n",
      "    accuracy                           0.73     15404\n",
      "   macro avg       0.74      0.73      0.73     15404\n",
      "weighted avg       0.74      0.73      0.73     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_DecisionTreeClassifier_md.joblib\")\n",
    "y11_pred = clf.predict(X11_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y11_test, y11_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y11_test, y11_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.6627499350817969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.76      0.67      0.72      5135\n",
      "     NEUTRAL       0.67      0.45      0.54      5135\n",
      "    POSITIVE       0.60      0.86      0.70      5134\n",
      "\n",
      "    accuracy                           0.66     15404\n",
      "   macro avg       0.68      0.66      0.65     15404\n",
      "weighted avg       0.68      0.66      0.65     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_NV_md.joblib\")\n",
    "y11_pred = clf.predict(X11_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y11_test, y11_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y11_test, y11_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.6769021033497793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.77      0.70      0.73      5135\n",
      "     NEUTRAL       0.69      0.49      0.57      5135\n",
      "    POSITIVE       0.61      0.84      0.71      5134\n",
      "\n",
      "    accuracy                           0.68     15404\n",
      "   macro avg       0.69      0.68      0.67     15404\n",
      "weighted avg       0.69      0.68      0.67     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_logistic_regesion_md.joblib\")\n",
    "y11_pred = clf.predict(X11_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y11_test, y11_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y11_test, y11_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7174110620618022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.82      0.73      0.77      5135\n",
      "     NEUTRAL       0.80      0.55      0.65      5135\n",
      "    POSITIVE       0.61      0.87      0.72      5134\n",
      "\n",
      "    accuracy                           0.72     15404\n",
      "   macro avg       0.74      0.72      0.71     15404\n",
      "weighted avg       0.74      0.72      0.71     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_svc_md.joblib\")\n",
    "y11_pred = clf.predict(X11_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y11_test, y11_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y11_test, y11_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2,2))\n",
    "bigrams = cv.fit_transform(data['review_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = pd.DataFrame(bigrams.toarray(), columns=cv.get_feature_names_out())\n",
    "X_2gram = bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2gram, y2 = oversampling(X_2gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y2_test.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_2gram, y2, test_size=0.33, random_state=37,stratify=y2)\n",
    "joblib.dump(X2_train, 'modelos/X2_train.pkl')\n",
    "joblib.dump(X2_test, 'modelos/X2_test.pkl')\n",
    "joblib.dump(y2_train, 'modelos/y2_train.pkl')\n",
    "joblib.dump(y2_test, 'modelos/y2_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = joblib.load('modelos/X2_train.pkl')\n",
    "y2_train = joblib.load('modelos/y2_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_trained_DecisionTreeClassifier.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X2_train, y2_train) \n",
    "joblib.dump(clf, \"modelos/2-gram_trained_DecisionTreeClassifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_trained_NV.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X2_train, y2_train)\n",
    "joblib.dump(clf, \"modelos/2-gram_trained_NV.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_logistic_regesion.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X2_train, y2_train)\n",
    "joblib.dump(clf, \"modelos/2-gram_logistic_regesion.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_trained_svc.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X2_train, y2_train)\n",
    "joblib.dump(clf, \"modelos/2-gram_trained_svc.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelos para evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_test = joblib.load('modelos/X2_test.pkl')\n",
    "y2_test = joblib.load('modelos/y2_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7294209296286679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.89      0.61      0.72      5135\n",
      "     NEUTRAL       0.84      0.70      0.76      5135\n",
      "    POSITIVE       0.59      0.88      0.71      5134\n",
      "\n",
      "    accuracy                           0.73     15404\n",
      "   macro avg       0.77      0.73      0.73     15404\n",
      "weighted avg       0.77      0.73      0.73     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_trained_DecisionTreeClassifier.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7174759802648663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.88      0.61      0.72      5135\n",
      "     NEUTRAL       0.80      0.66      0.72      5135\n",
      "    POSITIVE       0.59      0.88      0.71      5134\n",
      "\n",
      "    accuracy                           0.72     15404\n",
      "   macro avg       0.76      0.72      0.72     15404\n",
      "weighted avg       0.76      0.72      0.72     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_trained_NV.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.738314723448455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.90      0.63      0.74      5135\n",
      "     NEUTRAL       0.84      0.68      0.75      5135\n",
      "    POSITIVE       0.61      0.91      0.73      5134\n",
      "\n",
      "    accuracy                           0.74     15404\n",
      "   macro avg       0.78      0.74      0.74     15404\n",
      "weighted avg       0.78      0.74      0.74     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_logistic_regesion.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_trained_svc.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = CountVectorizer(ngram_range=(3,3),min_df=0.00005)\n",
    "trigrams = cv1.fit_transform(data['review_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = pd.DataFrame(trigrams.toarray(), columns=cv1.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3gram = trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3gram, y3 = oversampling(X_3gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y3_test.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X_3gram, y3, test_size=0.33, random_state=37,stratify=y3)\n",
    "joblib.dump(X3_train, 'modelos/X3_train.pkl')\n",
    "joblib.dump(X3_test, 'modelos/X3_test.pkl')\n",
    "joblib.dump(y3_train, 'modelos/y3_train.pkl')\n",
    "joblib.dump(y3_test, 'modelos/y3_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train = joblib.load('modelos/X3_train.pkl')\n",
    "y3_train = joblib.load('modelos/y3_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/3-gram_trained_DecisionTreeClassifier.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X3_train, y3_train) \n",
    "joblib.dump(clf, \"modelos/3-gram_trained_DecisionTreeClassifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/3-gram_trained_NV.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X3_train, y3_train)\n",
    "joblib.dump(clf, \"modelos/3-gram_trained_NV.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/3-gram_logistic_regesion.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X3_train, y3_train)\n",
    "joblib.dump(clf, \"modelos/3-gram_logistic_regesion.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/3-gram_trained_svc.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X3_train, y3_train)\n",
    "joblib.dump(clf, \"modelos/3-gram_trained_svc.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelos para evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_test = joblib.load('modelos/X3_test.pkl')\n",
    "y3_test = joblib.load('modelos/y3_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.5235003895092184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.85      0.26      0.40      5135\n",
      "     NEUTRAL       0.81      0.37      0.50      5135\n",
      "    POSITIVE       0.42      0.94      0.58      5134\n",
      "\n",
      "    accuracy                           0.52     15404\n",
      "   macro avg       0.69      0.52      0.50     15404\n",
      "weighted avg       0.69      0.52      0.50     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_trained_DecisionTreeClassifier.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.508828875616723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.80      0.27      0.41      5135\n",
      "     NEUTRAL       0.76      0.30      0.43      5135\n",
      "    POSITIVE       0.42      0.95      0.58      5134\n",
      "\n",
      "    accuracy                           0.51     15404\n",
      "   macro avg       0.66      0.51      0.47     15404\n",
      "weighted avg       0.66      0.51      0.47     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_trained_NV.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.5246689171643729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.83      0.29      0.43      5135\n",
      "     NEUTRAL       0.77      0.35      0.48      5135\n",
      "    POSITIVE       0.43      0.94      0.59      5134\n",
      "\n",
      "    accuracy                           0.52     15404\n",
      "   macro avg       0.68      0.52      0.50     15404\n",
      "weighted avg       0.68      0.52      0.50     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_logistic_regesion.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.5309010646585303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.70      0.36      0.47      5135\n",
      "     NEUTRAL       0.86      0.35      0.50      5135\n",
      "    POSITIVE       0.42      0.89      0.57      5134\n",
      "\n",
      "    accuracy                           0.53     15404\n",
      "   macro avg       0.66      0.53      0.51     15404\n",
      "weighted avg       0.66      0.53      0.51     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_trained_svc.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mineria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
