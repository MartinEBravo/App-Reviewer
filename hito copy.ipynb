{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hito 2 - AppEval\n",
    "\n",
    "CC5205 - Minería de Datos\n",
    "\n",
    "- Profesora: Jazmine Maldonado\n",
    "- Auxiliar: Fran Zautzik\n",
    "\n",
    "Integrantes:\n",
    "- Felipe Avendaño\n",
    "- Martín Bravo\n",
    "- Franco González\n",
    "- Daniel Radrigán\n",
    "- Felipe Valdebenito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "\n",
    "En la actualidad, las redes sociales constituyen una de las principales formas de comunicación en el mundo. Algunas de estas redes concentran una cantidad tan grande de personas que las usan, que una alternativa a elas suena como algo impensable. Aún así, algunas corporaciones lanzan su perspectiva de como debiese ser alguna red social en cuestion (séase de ejemplo, la existencia de Telegram frente a WhatsApp como aplicaciones de mensajería instantánea). Dichas redes han sido desarrolladas en base a estudios de mercado, análisis de información, y para este caso, se mencionara el feedback otorgado directamente por los usuarios que conforman la plataforma en sí.\n",
    "\n",
    "Comercialmente hablando, la retroalimentacion de los usuarios sobre una determinada aplicacion es determinante a la hora de realizar mejoras que atraigan y retengan usuarios dentro de la misma plataforma. Tomando esto en cuenta, dada la gran cantidad de comentarios negativos con descripciones vagas o de exagerada negatividad, se complejiza el poder obtener un feedback objetivo que indique precisamente las falencias de la app. Por estas razones, poder extraer determinados fragmentos que se frecuentan en comentarios negativos es de importancia para ayudar a las empresas a mantener la calidad de sus aplicaciones.\n",
    "\n",
    "Los datos que se usarán en el proyecto a presentar, corresponden a reviews de usuarios de aplicaciones de redes sociales, en particular, la aplicación Threads. El estudio de estos datos puede permitir el observar que aspectos de las aplicaciones valoran los usuarios. Tambien permite entender las razones del porque no gusta determinada caracteristica. La elección de datos se basa en la relevancia que poseen para el desarrollo de nuevas redes sociales o mejoras de las ya existentes.\n",
    "\n",
    "Para las emperesas es de particular interés el uso de tecnicas de mineria de datos para obtener los aspectos criticados en las reviews de la app a partir del análisis del lenguaje empleado.\n",
    "\n",
    "Como bien se ha mencionado, estudiar estos datos nos permite entender cuales son los aspectos a mejorar de una app, los cuales no pueden ser conocidos mediante una simple puntuación numérica (e.g. 1-5 estrellas), pues solo indica el nivel de satisfacción que el usuario tiene sobre la app, sin otorgar detalle sobre la razón de dicha calificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploración de Datos\n",
    "\n",
    "Por medio del uso de Python, junto con variadas librerias para la manipulación del dataset escogido, se procedera a la obtención de tablas y gráficos para extraer información general sobre los comentarios dados a la aplicación Threads. Dicha aplicación se basa en la publicación de mensajes breves a modo de que cada usuario participa en \"foros\" según los tópicos más importantes del día."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import seaborn as sns # plotting\n",
    "import string # string manipulation\n",
    "import re # regular expressions\n",
    "import nltk # text manipulation\n",
    "\n",
    "from tqdm import trange # progress bar\n",
    "from nltk import tokenize # text manipulation\n",
    "from nltk.corpus import stopwords # text manipulation\n",
    "from nltk.stem import WordNetLemmatizer # text manipulation\n",
    "from nltk.probability import FreqDist # text manipulation\n",
    "from collections import Counter # text manipulation\n",
    "from sklearn.feature_extraction.text import CountVectorizer # text manipulation\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator # wordcloud generator\n",
    "from IPython.display import display # image display\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se mostrará una vista preliminar del dataset escogido. Para ver cantidad de columnas y los tipos de datos que se manejan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"threads.csv\") # carga del dataset a usar como variable\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicho dataset cuenta con 4 columnas, y 32910 filas. Las columnas son:\n",
    "- Source: La procedencia de los comentarios (según el sistema operativo y la tienda de aplicaciones de la cual se descargó),\n",
    "- Review Description: El comentario publicado, el cual contiene el detalle sobre la calificación otorgada a la aplicación.\n",
    "- Rating: La puntuación otorgada, en una escala de 1 a 5, con 1 como puntuacion mala y 5 como excelente.\n",
    "- Review Date: Fecha de publicación de la reseña, con detalle sobre el día, mes, año y hora de publicación.\n",
    "\n",
    "Se hará una revisión a la cantidad de reseñas segun la calificación otorgada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[\"rating\"].value_counts()) # contar la cantidad de reviews recibidas segun el rating de 1 a 5\n",
    "\n",
    "# muestra mediana, media, desviación estándar, mínimo y máximo de la variable \"replies\"\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el promedio de los ratings es de 3.4, lo cual es un valor bastante bajo, además podemos observar que la mayoría de reseñas son de 5 estrellas, y luego vienen las de 1 estrella, esto nos sugiere dividir las reseñas en distintos grupos.\n",
    "\n",
    "A partir de estos datos, se puede generar un gráfico de pastel. Primero, se realizará una conversión del rating según rangos. Dichos rangos son: 1-2 estrellas como NEGATIVO, 3-4  estrellas como NEUTRAL y 5 estrellas como POSITIVO. El gráfico generado se muestra a continuación.\n",
    "\n",
    "La razón de esta elección es debido a que los comentarios de 1-2 estrellas suelen ser de tipos negativos, mientras que los de 5 estrellas suelen ser positivos. Los comentarios de 3-4 estrellas se pondrán como neutrales, ya que dicen algo positivo de la aplicación, pero también mencionan algo negativo (en un principio se dejó neutral como 3 estrellas pero esto generaba muy poca cantidad de reseñas neutrales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para convertir el rating a palabras\n",
    "def ratingTransform(rating):\n",
    "    if rating <= 2:\n",
    "        return \"NEGATIVE\"\n",
    "    elif rating <= 4:\n",
    "        return \"NEUTRAL\"\n",
    "    else:\n",
    "        return \"POSITIVE\"\n",
    "\n",
    "# creacion del grafico de pie de las reviews segun rating\n",
    "data[\"rating\"] = data[\"rating\"].apply(ratingTransform)\n",
    "plt.pie(data[\"rating\"].value_counts(), labels=data[\"rating\"].value_counts().index, autopct='%1.1f%%')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que la mayoría de las reseñas son positivas, siguiendo en cantidad las negativas y por último las neutrales. Esto sugiere que la aplicación se considera buena, pero tiene algunos problemas que se pueden mejorar.\n",
    "\n",
    "Ya que nuestro dataset contiene en su mayoría texto, se generarán columnas que ayudarán a analizarlo. Estas columnas serán:\n",
    "- Review Length: Largo del comentario.\n",
    "- Word Count: Cantidad de palabras que contiene el comentario.\n",
    "- Mean Word Length: Promedio de largo de las palabras del comentario.\n",
    "- Mean Sentence Length: Promedio de largo de las oraciones del comentario.\n",
    "\n",
    "Estas columnas apoyarán en la realización de gráficos basados en atributos provenientes del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabla generada con el largo en caracteres de las reviews escritas\n",
    "data['Length'] = data['review_description'].str.len()\n",
    "# numero de palabras en la primera review del dataset\n",
    "word_count = data['review_description'][0].split()\n",
    "# funcion para separar una oracion y contar la cantidad de palabras que posee\n",
    "def word_count(review):\n",
    "    review_list = review.split()\n",
    "    return len(review_list)\n",
    "# generacion de nueva columna de cantidad de palabras por review\n",
    "data['Word_count'] = data['review_description'].apply(word_count)\n",
    "# largo promedio de las palabras en cada review\n",
    "data['mean_word_length'] = data['review_description'].map(lambda rev: np.mean([len(word) for word in rev.split()]))\n",
    "# largo promedio de las oraciones en cada review\n",
    "np.mean([len(sent) for sent in tokenize.sent_tokenize(data['review_description'][0])])\n",
    "data['mean_sent_length'] = data['review_description'].map(lambda rev: np.mean([len(sent) for sent in tokenize.sent_tokenize(rev)]))\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la tabla anterior, se pueden extraer los siguientes gráficos, cada uno basado en cada una de las columnas creadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# creacion del boxplot de las palabras\n",
    "def visualize(col, ind=0, max_ys_k=[0.012,0.07,0.2,0.02], max_xs_k=[400,100,15,200], max_ys_b =[200,50,10,150]):\n",
    "    \n",
    "    print()\n",
    "    plt.plot(1,2,1)\n",
    "    sns.boxplot(y=data[col], hue=data['rating'])\n",
    "    plt.title('Distribución de '+col)\n",
    "    plt.ylabel(col, labelpad=12.5)\n",
    "    plt.ylim(0,max_ys_b[ind])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(1,2,2)\n",
    "    sns.kdeplot(data=data, x=col, hue='rating')\n",
    "    plt.legend(data['rating'].unique())\n",
    "    plt.ylim([0,max_ys_k[ind]])\n",
    "    plt.xlim([0,max_xs_k[ind]])\n",
    "    plt.title('Estimación de densidad de '+col)\n",
    "    plt.xlabel(col, labelpad=12.5)\n",
    "    plt.ylabel('Frecuencia relativa')\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "features = data.columns.tolist()[4:]\n",
    "print(features)\n",
    "i = 0\n",
    "for feature in features:\n",
    "    visualize(feature,ind=i)\n",
    "    i+=1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones con respecto a los gráficos:\n",
    "\n",
    "- Review Length:\n",
    "\n",
    "La mayoria de los largos de los comentarios son menores a 75 caracteres, es decir, los comentarios suelen ser cortos, en especial los comentarios positivos. Podemos notar que mientras los comentarios positivos suelen ser cortos, los comentarios neutrales estan mas equilibrados y los comentarios negativos también, auque estos últimos también tiene una alta frecuencia de comentarios cortos.\n",
    "\n",
    "Por lo anterior, se puede decir que los comentarios con mayor información deberian ser aquellos que muestran descontento por la aplicación, probablemente por que en su comentario hablan del problema que tienen con la aplicación, mientras que comentarios más positivos puede ser que solo destaquen aquello que les gusta sin necesidad de extenderse mucho en el porque.\n",
    "\n",
    "- Word Count:\n",
    "\n",
    "Las conclusiones anteriores también se extienden a la cantidad de palabras utilizadas en el comentario, ya que estan muy relacionados. La frecuencia de la cantidad de palabras también esta concentrada en valores bajos y se comporta igual que el largo con respecto a comentarios positivos, neutrales y negativos.\n",
    "\n",
    "- Mean Word Length:\n",
    "\n",
    "Podemos observar que el largo promedio de las palabras utilizadas pareciera seguir una distribucion normal, lo cual tine relacion con las palabras que se utilizan para escribir las reseñas, que una reseña tenga un largo de palabras muy alto indicaria la utilizacion de un lenguaje mas tecnico y complicado, en cambio aquellos comentarios con promedios de palabras mas cortos problablemente utilizan muchas palabras que aportan poco al mensaje.\n",
    "\n",
    "También podemos notar que en general los comentarios positivos estan mas distribuidos en cuanto al largo promedio de las palabras, en cambio los comentarios negativos se concentran mucho más en torno al valor promedio.\n",
    "\n",
    "- Mean Sentence Length:\n",
    "\n",
    "Con respecto al largo promedio de las oraciones de los comentarios podemos ver que en general también se concentran en valores bajos, pero esto es mas notorio para los comentarios positivos que probablemente solo destacan lo positivo de la aplicacion mientras que los neutrales y los negativos estan más distribuidos y tienen mayor frecuencia en valores más grandes problablemente porque muestran su descontento o describen su problema con la aplicación, lo cual los puede llevar a escribir un comentario más largo y complejo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de frecuencia de términos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos uso de la librería NLTK, la cual permite realizar un análisis de frecuencia de términos. Para esto, primero se debe limpiar el texto, eliminando signos de puntuación, números, stopwords, etc. Esto se realiza gracias a que internamente NLTK posee una lista de stopwords en inglés, la cual se usará para eliminarlas. Además, se hará uso de la librería string para eliminar signos de puntuación y números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(review):\n",
    "    \n",
    "    review = review.lower()\n",
    "    review = re.sub('[^a-z A-Z 0-9-]+', '', review)\n",
    "    review = \" \".join([word for word in review.split() if word not in stopwords.words('english')])\n",
    "    \n",
    "    return review\n",
    "\n",
    "data['review_description'] = data['review_description'].apply(clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def corpus(text):\n",
    "    text_list = text.split()\n",
    "    return text_list\n",
    "\n",
    "data['review_lists'] = data['review_description'].apply(corpus)\n",
    "\n",
    "corpus = []\n",
    "for i in trange(data.shape[0], ncols=150, nrows=10, colour='green', smoothing=0.8):\n",
    "    corpus += data['review_lists'][i]\n",
    "\n",
    "mostCommon = Counter(corpus).most_common(10)\n",
    "\n",
    "words = []\n",
    "freq = []\n",
    "for word, count in mostCommon:\n",
    "    words.append(word)\n",
    "    freq.append(count)\n",
    "\n",
    "sns.barplot(x=freq, y=words)\n",
    "plt.title('Top 10 Palabras más comunes')\n",
    "plt.show()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con respecto a las palabras más comunes, es dificil poder concluir algo ya que no se tiene el contexto en el que se estan utilizando pero aun asi se pueden decir algunas cosas.\n",
    "\n",
    "Que tanto \"app\" como \"instagram\" esten entre las palabras más frecuentes no es extraño ya que hacen referencia a la propia aplicacion sobre la cual trata el comentario.\n",
    "\n",
    "Una palabra que puede resultar más extraño que sea tan comun es \"twitter\", esto probablemente esta relacionado con que son competencia, por lo que los usuarios siempre van a hacer comparaciones para decir si una aplicacion es mejor o peor a otra, en este caso no podemos identificar el contexto en el que se utiliza la palabra \"twitter\" pero podemos suponer que se utiliza para decir que instagram es peor o mejor que \"twitter\" en alguna de sus características.\n",
    "\n",
    "Otras palabras como \"good\", \"like\", \"nice\" y \"better\" probablemente son parte de comentarios positivos, aunque no significa que no puedan estar en uno neutral o negativo, estan palabras tambien son bastante comunes y son de un uso muy general, además los comentarios positivos representan gran parte del data set, por lo estan palabras no nos aportan tanto.\n",
    "\n",
    "Otra palabra comun es \"dont\", pero esta palabra es de un uso muy general asi que no sorprende que sea frecuente, además no podemos interpretar el contexto en el que se utiliza ya que \"dont\" podría ser utilizado tanto para un comentario positivo como negativo, aún así uno prodría pensar que la palabra estaría más relacionada con comentarios negativos y prodrá relacionarse con algo que quizá no les gusta a los usuarios o no les funciona.\n",
    "\n",
    "Las palabras \"threads\" y \"account\" hacen referencia a caracteristicas de la aplicación, es difícil concluir algo ya que el comentario puede ser positivo o negativo, lo único que podemos decir es que el comentario probablemente es más extenso en su contenido al estar hablando de algún tema en específico de la aplicación.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También, posterior a la limpieza, es posible generar nubes de palabras basadas en la cantidad de palabras por Rating, esto nos permitira un mejor analizis de las palabras frecuentes ya que tendremos un mayor contexto para poder realizar el analisis. Los Wordclouds que se puedieron extraer son los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# generacion de la wordcloud para definir cuales pueden ser las palabras mas importantes\n",
    "def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), color = 'white',\n",
    "                   title = None, title_size=40, image_color=False):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    more_stopwords = {'u', \"im\"}\n",
    "    stopwords = stopwords.union(more_stopwords)\n",
    "\n",
    "    wordcloud = WordCloud(background_color=color,\n",
    "                    stopwords = stopwords,\n",
    "                    max_words = max_words,\n",
    "                    max_font_size = max_font_size, \n",
    "                    random_state = 42,\n",
    "                    width=400, \n",
    "                    height=200,\n",
    "                    mask = mask)\n",
    "    wordcloud.generate(str(text))\n",
    "    \n",
    "    plt.figure(figsize=figure_size)\n",
    "    if image_color:\n",
    "        image_colors = ImageColorGenerator(mask)\n",
    "        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\")\n",
    "        plt.title(title, fontdict={'size': title_size,  \n",
    "                                  'verticalalignment': 'bottom'})\n",
    "    else:\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n",
    "                                  'verticalalignment': 'bottom'})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Neutral_rev = data[data[\"rating\"] == \"NEUTRAL\"]\n",
    "plot_wordcloud(Neutral_rev.review_description,color='white',max_font_size=100,title_size=30,title=\"WordCloud de reviews neutrales\")\n",
    "Posit_rev = data[data[\"rating\"] == \"POSITIVE\"]\n",
    "plot_wordcloud(Posit_rev.review_description,color='white',max_font_size=100,title_size=30,title=\"WordCloud de reviews positivas\")\n",
    "Neg_rev = data[data[\"rating\"] == \"NEGATIVE\"]\n",
    "plot_wordcloud(Neg_rev.review_description,color='white',max_font_size=100,title_size=30,title=\"WordCloud de reviews negativas\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los $N-$ gramas mas frecuentes\n",
    "\n",
    "Los $N-$ gramas son secuencias de $N$ palabras consecutivas en un texto. Estos nos permitirán dar un mayor contexto a las palabras con mayor frecuencia recién vistas. A continuación veremos los 10 $2-$ gramas y $3-$ gramas más frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cv = CountVectorizer(ngram_range=(2,2))\n",
    "bigrams = cv.fit_transform(data['review_description'])\n",
    "\n",
    "count_values = bigrams.toarray().sum(axis=0)\n",
    "ngram_freq = pd.DataFrame(sorted([(count_values[i], k) for k, i in cv.vocabulary_.items()], reverse = True))\n",
    "ngram_freq.columns = [\"frequency\", \"ngram\"]\n",
    "\n",
    "sns.barplot(x=ngram_freq['frequency'][:10], y=ngram_freq['ngram'][:10])\n",
    "plt.title('Top 10 2-gramas más comunes')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 2-grama nos permite complementar la informacion anterios y tener un mayor contexto ya ahora son grupos de palabras y no palabras sueltas, esto nos permite obtener mejores conclusiones con respecto a palabras mas frecuentes. Por ejemplo podemos ver que en general \"good\" va seguido de \"app\", lo cual refuerza algunas de las cosas dichas anteriormente como que las reseñas positivas van dirigidas a temas mas generales y no tanto a un problemas más específico. También vemos que esta \"better twitter\" o \"copy twitter\", lo cual también refuerza parte de lo dicho anteriormente ya que estos comentarios, problablemente negativos, comparan la aplicación con twitter y valora una aplicación por sobre la otra. Otros comentarios siguen sin tener mucho sentido al no tener contexto, como \"social media\", frase que tiene mucha relacion con la aplicación pero es no se puede decir con certeza si se esta utilizando en un contexto positivo, negativo o neutral. El tener a \"elon musk\" como 2-grama frecuente problablemente se relaciona con la rivalidad entre aplicaciones y todos los eventos recientes con respecto a Elon Musk y la compra de twitter, lo cual probablemente provoco un aumento significativo en los comentarios con respecto a ese tema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se mostrará lo obtenido con 3-gramas, siendo las frases de tres palabras mas recurrentes en las reseñas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cv1 = CountVectorizer(ngram_range=(3,3))\n",
    "trigrams = cv1.fit_transform(data['review_description'])\n",
    "count_values = trigrams.toarray().sum(axis=0)\n",
    "ngram_freq = pd.DataFrame(sorted([(count_values[i], k) for k, i in cv1.vocabulary_.items()], reverse = True))\n",
    "ngram_freq.columns = [\"frequency\", \"ngram\"]\n",
    "\n",
    "sns.barplot(x=ngram_freq['frequency'][:10], y=ngram_freq['ngram'][:10])\n",
    "plt.title('Top 10 3-gramas más comunes')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con 3-gramas tenemos incluso más información que antes, aunque siguen habiendo frases que podrian utilizarse en casi cualquier contexto.\n",
    "\n",
    "Podemos ver que hay algunos del estilo \"something wetn wrong\", que problablemente son comentarios negativos hablando del mal funcionamiento de la app y puede que sea un comentario más complejo de lo normal a al contener más que solo una crítica general.\n",
    "\n",
    "También podemos notar que hay muchas frases con delete como \"wihtout deleting instagram\", \"delete instagram account\" o \"delete threads account\", solo leyendo estas frases no se puede concluir a que estan haciendo referencia pero probablemente estan describiendo algún problema que tuvieron con el uso de la aplicación, por lo que probablemente son comentarios negativos, y si hay muchas personas con el mismo problema tiene sentido que esten entre las frases más frecuentes al ser un problema que afecta a muchos usuarios.\n",
    "\n",
    "Como se pudo ver en los otros casos, persiste la rivalidad entre aplicaciones con comentarios como \"much better twitter\", de hecho esta frase complementa todo lo que se ha dicho anteriormente y el como muchos usuarios prefieren twitter por sobre instagram. \n",
    "\n",
    "El 3-grama más común es \"people dont follow\", podriamos decir que el comentario es negativo ya que pareciera ser una queja con respecto a la aplicación o a los usuarios de la misma, aunque la frase sigue sin tener el contexto necesario para poder hacer una conclusión con respecto a porque aparece entre las frases más comunes entre las reseñas. \n",
    "\n",
    "Para el caso de los 3-gramas podemos notar que la mayoría de las frases parecieran estar relacionadas con aspectos negativos de la aplicación, contrario a lo que vimos en el caso de palabras y 2-gramas más frecuentes. Lo anterior parece tener relación con una observacion anterior en la que se dijo que los comentarios positivos probablemente destacan aquello que les gusta mientras que los comentarios más neutrales o negativos describen su problema o hablan de forma más especifica con respecto a alguna característica de la aplicación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preguntas y Problemas\n",
    "\n",
    "1. ¿Es posible predecir si una reseña es positiva o negativo dado ciertos N-gramas?\n",
    "2. ¿que cluster se forman?\n",
    "3. ¿como cambian las revies segun fecha como medida de la versión?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hito 2\n",
    "\n",
    "Primero vamos a añadir y editar algunas columnas para poder trabajar mejor con los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminaremos review_lists ya que solo eran para visualizar los datos\n",
    "#data = data.drop(['review_lists'], axis=1)\n",
    "# Pasaremos las fechas a formato datetime\n",
    "# Dias\n",
    "data['review_date'] = pd.to_datetime(data['review_date']).apply(lambda x: (x.value)//(1_000_000_000*60*60*24))\n",
    "# normalizar 0 a 1  las fechas\n",
    "data['review_date'] = (data['review_date'] - data['review_date'].min()) / (data['review_date'].max() - data['review_date'].min())\n",
    "# normalizar 0 a 1 length, wordcount, mean_word_length, mean_sent_length\n",
    "data['Length'] = (data['Length'] - data['Length'].min()) / (data['Length'].max() - data['Length'].min())\n",
    "data['Word_count'] = (data['Word_count'] - data['Word_count'].min()) / (data['Word_count'].max() - data['Word_count'].min())\n",
    "data['mean_word_length'] = (data['mean_word_length'] - data['mean_word_length'].min()) / (data['mean_word_length'].max() - data['mean_word_length'].min())\n",
    "data['mean_sent_length'] = (data['mean_sent_length'] - data['mean_sent_length'].min()) / (data['mean_sent_length'].max() - data['mean_sent_length'].min()) #\n",
    "# Pasaremos algunas columnas a categoricas source, rating a int\n",
    "data['source'] = data['source'].apply(lambda x: 1 if x == \"Google Play\" else 0)\n",
    "\n",
    "def ratingTransform(rating):\n",
    "    if rating == \"POSITIVE\":\n",
    "        return 2\n",
    "    elif rating == \"NEUTRAL\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data['rating'] = data['rating'].apply(ratingTransform)\n",
    "\n",
    "\n",
    "# verifiquemos los tipos de columna\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiremos nuestro $X$ y nuestro $Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(data[\"review_description\"])\n",
    "\n",
    "vectorized = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "data = data.drop(['review_description'], axis=1)\n",
    "data = pd.concat([data, vectorized], axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos X e Y\n",
    "X = data.drop(['rating'], axis=1)\n",
    "Y = data['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizar datos\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1])\n",
    "plt.xlabel('Componente 1')\n",
    "plt.ylabel('Componente 2')\n",
    "plt.title('PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans\n",
    "sse = []\n",
    "\n",
    "clusters = list(range(1,16))\n",
    "for i in clusters:\n",
    "    kmeans = KMeans(n_clusters=i, n_init=\"auto\", max_iter=100, random_state=42).fit(X) # fit retorna a self\n",
    "    sse.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clusters, sse, marker=\"o\")\n",
    "plt.xlabel('Número de Clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividiremos el dataset para test y train, tomando el clustering usaremos x categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=37,stratify=Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"nigger\"\n",
    "print(clf.predict(vectorizer.transform([review])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train) \n",
    "y_pred = clf.predict(X_test) \n",
    "print(\"Accuracy en test set:\", accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(23,10))\n",
    "tree.plot_tree(decision_tree=clf, fontsize=7, max_depth = 4, feature_names=vectorizer.get_feature_names_out(), class_names=clf.classes_, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = X.columns\n",
    "l = [1039, 2633, 3759, 4222, 4185, 2672, 6158]\n",
    "\n",
    "print(\"La palabra mas relevante para la decision de categorias es: \"+columnas[l[0]])\n",
    "print(\"Luego les siguen en el arbol las palabras: \"+columnas[l[1]]+ \" e \"+columnas[l[2]])\n",
    "print(\"A altura 3 en el arbol, las palabras son: \")\n",
    "for i in l[3:]:\n",
    "    print(\"  \"+columnas[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que las palabras mas significativas no son buenas para evaluar bien a que se refiere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2,2))\n",
    "bigrams = cv.fit_transform(data['review_description'])\n",
    "X = pd.DataFrame(bigrams.toarray())\n",
    "Y = data[\"rating\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.33, random_state=37,stratify=Y)\n",
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train) \n",
    "y_pred = clf.predict(X_test) \n",
    "print(\"Accuracy en test set:\", accuracy_score(y_test, y_pred)) \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "tree.plot_tree(decision_tree=clf, fontsize=7, max_depth = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = X.columns\n",
    "l = [48842, 12963, 95756, 21456, 101894, 24732]\n",
    "\n",
    "print(\"La palabra mas relevante para la decision de categorias es: \"+str(columnas[l[0]]))\n",
    "print(\"Luego les siguen en el arbol las palabras: \"+str(columnas[l[1]])+ \" e \"+str(columnas[l[2]]))\n",
    "print(\"A altura 3 en el arbol, las palabras son: \")\n",
    "for i in l[3:]:\n",
    "    print(\"  \"+str(columnas[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
