{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\felip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\felip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Librerías\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import seaborn as sns # plotting\n",
    "import string # string manipulation\n",
    "import re # regular expressions\n",
    "import nltk # text manipulation\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from tqdm import trange # progress bar\n",
    "from nltk import tokenize # text manipulation\n",
    "from nltk.corpus import stopwords # text manipulation\n",
    "from nltk.stem import WordNetLemmatizer # text manipulation\n",
    "from nltk.probability import FreqDist # text manipulation\n",
    "from collections import Counter # text manipulation\n",
    "from sklearn.feature_extraction.text import CountVectorizer # text manipulation\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator # wordcloud generator\n",
    "from IPython.display import display # image display\n",
    "from PIL import Image\n",
    "\n",
    "#hito 2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "import joblib # guardar modelos\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propuesta experimental\n",
    "\n",
    "Como propuesta experimental, en este proyecto se hará uso de los métodos de clustering para la pregunta 2 y clasificación para la 1 y 3. Dado que clasificación es un método supervisado, adicionalmente se realizarán pruebas para obtener métricas de desempeño para escoger el mejor método de clasificación, mientras que, para el caso de clustering, al ser no supervisado, se deberán usar métodos para validar los clusters generados.\n",
    "\n",
    "## Pregunta 1\n",
    "\n",
    "Para responder la primera pregunta, se ha realizado un preprocesamiento que consta de, en primer lugar, la conversión del rating a palabras, a modo de limitar las categorías de originalmente 5 a 3. En segundo lugar, se hace la limpieza del dataset de aquellas palabras poco útiles para nuestro propósito, por lo que se filtran números, stopwords y se actualiza todo el texto del dataset de reseñas a minúsculas. Dado que, aún con la conversión de ratings existen categorías que quedan subrepresentadas en comparación a otras, se hace un oversampling basado en el rating de las reseñas para obtener un balanceo de datos para que los modelos generados sean mas correctos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para convertir el rating a palabras\n",
    "def ratingTransform(rating):\n",
    "    if rating <= 2:\n",
    "        return \"NEGATIVE\"\n",
    "    elif rating <= 4:\n",
    "        return \"NEUTRAL\"\n",
    "    else:\n",
    "        return \"POSITIVE\"\n",
    "\n",
    "# funcion para realizar la limpieza del texto en el dataset\n",
    "def clean(review):\n",
    "    review = review.lower()\n",
    "    review = re.sub('[^a-z A-Z 0-9-]+', '', review)\n",
    "    review = \" \".join([word for word in review.split() if word not in stopwords.words('english')])\n",
    "    return review\n",
    "\n",
    "# funcion para hacer oversampling de los datos que se encuentran desbalanceados\n",
    "def oversampling(X,y):\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_resample, y_resample = ros.fit_resample(X, y)\n",
    "    return (X_resample, y_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prosiguiendo con los N-gramas, se verá lo que ocurre con los 1-gramas. Primero, se procede con la vectorización, ya que se quiere convertir el texto a una forma que los algoritmos de aprendizaje que se usarán posteriormente puedan entender y procesar. En este caso, dado que en el preprocesamiento se estableció la necesidad de hacer oversampling a los datos, la vectorización será útil para luego poder hacer dicho oversampling. Finalmente, se realiza la división de los datos entre datos de prueba (con el 33% de los datos destinado para eso) y datos de entrenamiento. Adicionalmente, se usarán funciones extras otorgadas por la librería “joblib”, la cual será de utilidad para guardar los datos procesados, para no tener necesidad de ejecutar todo desde el principio, y asi conservar el entrenamiento. Esto es de especial importancia por lo que se mencionara a continuación.\n",
    "\n",
    "Luego de almacenar la data útil para los algoritmos, se procede con el entrenamiento de los modelos. Para estos, se usarán principalmente los de clasificación, en particular Árboles de decisión, Naive Bayes, regresión logística y Support Vector Classifier. La elección de los modelos de clasificación esta guiada por el saber que tan viable es obtener una reseña positiva dados ciertos N-gramas. Ya que el entrenamiento es la parte mas pesada de este proceso, también se ha decidido el guardar la data mediante los comandos de joblib.\n",
    "\n",
    "Cabe mencionar que en principio se realizarón comparaciones con respecto a los resultados obtenidos entre limitaciones a la vectorización eliminando todo aquel dato que tuviese baja representatividad y el dataset sin alteraciones. Los resultados para 1-gramas arrojaron las métricas que se muestran a continuación:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Datos obtenidos en el dataset sin restricciones    |      Datos obtenidos en el dataset con min_df=0.0005\n",
    "         Accuracy en test set: 0.753245910153207       |         Accuracy en test set: 0.7290963386133472\n",
    "                                                       |\n",
    "              precision    recall  f1-score   support  |                precision    recall  f1-score   support\n",
    "                                                       |\n",
    "    NEGATIVE       0.83      0.76      0.79      5135  |      NEGATIVE       0.81      0.73      0.77      5135\n",
    "     NEUTRAL       0.76      0.74      0.75      5135  |       NEUTRAL       0.74      0.69      0.72      5135\n",
    "    POSITIVE       0.69      0.76      0.73      5134  |      POSITIVE       0.65      0.76      0.70      5134\n",
    "                                                       |\n",
    "    accuracy                           0.75     15404  |      accuracy                           0.73     15404\n",
    "    macro avg      0.76      0.75      0.75     15404  |     macro avg       0.74      0.73      0.73     15404\n",
    "    weighted avg   0.76      0.75      0.75     15404  |  weighted avg       0.74      0.73      0.73     15404"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es posible observar, las métricas obtenidas al limitar la vectorización del dataset son levemente inferiores a las métricas obtenidas con el dataset sin restricciones. Por esta razón, en favor de buscar el resultado más adecuado, y dado un posible aumento en las diferencias de metricas a medida que se procede con los siguiente N-gramas, se ha decidido usar los datasets sin alteraciones, pese a los tiempos de ejecución más lentos.\n",
    "\n",
    "Se procede a cargar los modelos con \"joblib\" y a extraer las principales métricas de desempeño para medir cual de los modelos ha sido el mas confiable con el entrenamiento dado. Estas métricas ayudarán en la comparación de modelos para decidir cual de ellos es mejor para poder responder la pregunta planteada. Tanto para 2-gramas como 3-gramas, se sigue el mismo procedimiento descrito anteriormente. Cabe resaltar la importancia de la librería joblib, ya que el procesamiento del entrenamiento de los modelos es una tarea conocida por ser pesada computacionalmente hablando. Queda en el anexo todo el código descrito en esta explicación, mientras que en la sección de Experimento preliminar se presentan los principales resultados.\n",
    "\n",
    "## Pregunta 2\n",
    "\n",
    "Para la segunda pregunta, se siguen los mismos pasos del preprocesamiento en la pregunta anterior, añadiéndose la adición y edición de nuevas columnas que ayudarán en el trabajo de visualización de los datos. Se harán cambios de formato, eliminación de datos que no sean de interés para esta sección, se normalizarán datos y, principalmente, se cambiará el formato de muestra del rating, ya que para clustering se necesitara que este dato se exprese como valor entero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo que muestre parte del preprocesamiento adicional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definirán los valores X e Y que servirán para la formación de los grupos con los cuales los algoritmos de clustering trabajarán, y, usando X, se procede con Analisis de Componentes Principales, a modo de reducir tanto la dimensionalidad, como la complejidad de los datos, esto para que sea más fácil hallar patrones visibles en los clusters.\n",
    "\n",
    "Los métodos de clustering a utilizar son, en principio, K-Means en un rango de 1 a 10 clusters. Esto determinará cual sería la cantidad de clusters ideal para poder responder la pregunta, por lo que adicionalmente se contará con el método del codo para determinar esto.\n",
    "\n",
    "Para la validación, se contara con el uso de matrices de similitud, las cuales otorgarán una inspección visual sobre que método de clustering resulta mas efectivo a la hora de obtener clusters de los datos\n",
    "\n",
    "## Pregunta 3\n",
    "\n",
    "Para responder la tercera pregunta, se hará nuevamente uso de los métodos de clasificación, esta vez iniciando con el dataset original y con un preprocesamiento leve, basado en cambios de formatos como el aspecto mas importante a considerar.\n",
    "\n",
    "Primero, se hará una visualización sobre el comportamiento de reseñas por tiempo, mostrando la cantidad de reseñas obtenidas en un periodo de tiempo, esto por cada valor de rating. Luego, se procede con la vectorización y entrenamiento de modelos de clasificación, usando en este caso Árboles de decisión con distintos criterios, Dummy Classifier, Gausiana Naive Bayes, K-Neighbors y SVC. De los resultados generados por cada modelo se extraen sus métricas de desempeño, para obtener aquel algoritmo que se haya comportado mejor a la hora de realizar el entrenamiento, o bien, aquel que se haya desempeñado mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo de apoyo de la idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, para ver la exactitud de los métodos, se usarán matrices de confusión para obtener las métricas de desempeño de manera mas visual. Se realizará adicionalmente una validación cruzada entre Árboles de decisión y GridSearchCV, esto ya que la validación proporciona una visualización de la medida mas fiable del rendimiento de los modelos ejecutados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento preliminar\n",
    "## Pregunta 1\n",
    "\n",
    "Aqui se añaden los principales resultados obtenidos de la experimentación en esta pregunta. Se mostrarán las tablas con las métricas de desempeño obtenidas por cada N-grama del 1 al 3. Para simplificación de la muestra, P = precision, R = recall, F1 = F1-score y S = support. A su vez, los modelos se nombran como DTC = DecisionTreeClassifier, NB = Naive Bayes, LR = Regresión logistica y SVC = Support Vector Machine.\n",
    "\n",
    "                         1-gram                     2-grama                    3-grama\n",
    "          \n",
    "    Accuracy test set: 0.753245910153207  |      0.7294209296286679  |  \n",
    "  \n",
    "           > DTC  P     R     F1    S     |  P     R     F1    S     |  P     R     F1    S     \n",
    "\n",
    "        NEGATIVE  0.83  0.76  0.79  5135  |  0.89  0.61  0.72  5135  |  \n",
    "         NEUTRAL  0.76  0.74  0.75  5135  |  0.84  0.70  0.76  5135  |  \n",
    "        POSITIVE  0.69  0.76  0.73  5134  |  0.59  0.88  0.71  5134  |  \n",
    "\n",
    "        accuracy              0.75 15404  |              0.73 15404  |  \n",
    "       macro avg  0.76  0.75  0.75 15404  |  0.77  0.73  0.73 15404  |  \n",
    "    weighted avg  0.76  0.75  0.75 15404  |  0.77  0.73  0.73 15404  |  \n",
    "    \n",
    "    --------------------------------------+--------------------------+----------------------------\n",
    "    \n",
    "    Accuracy test set: 0.6999480654375487 |      0.7174759802648663\n",
    "    \n",
    "            > NB  P     R     F1    S     |  P     R     F1    S     |  P     R     F1    S   \n",
    "\n",
    "        NEGATIVE  0.80  0.71  0.75  5135  |  0.88  0.61  0.72  5135  |  \n",
    "         NEUTRAL  0.68  0.56  0.62  5135  |  0.80  0.66  0.72  5135  |  \n",
    "        POSITIVE  0.64  0.83  0.72  5134  |  0.59  0.88  0.71  5134  |  \n",
    "\n",
    "        accuracy              0.70 15404  |              0.72 15404  |  \n",
    "       macro avg  0.71  0.70  0.70 15404  |  0.76  0.72  0.72 15404  |  \n",
    "    weighted avg  0.71  0.70  0.70 15404  |  0.76  0.72  0.72 15404  |  \n",
    "    \n",
    "    --------------------------------------+--------------------------+----------------------------\n",
    "    \n",
    "    Accuracy test set: 0.7331212672033238 |       0.738314723448455  |  \n",
    "            \n",
    "            > LR  P     R     F1    S     |  P     R     F1    S     |  P     R     F1    S   \n",
    "\n",
    "        NEGATIVE  0.82  0.75  0.78  5135  |  0.90  0.63  0.74  5135  |  \n",
    "         NEUTRAL  0.75  0.61  0.67  5135  |  0.84  0.68  0.75  5135  |  \n",
    "        POSITIVE  0.66  0.84  0.74  5134  |  0.61  0.91  0.73  5134  |  \n",
    "\n",
    "        accuracy              0.73 15404  |              0.74 15404  |  \n",
    "       macro avg  0.74  0.73  0.73 15404  |  0.78  0.74  0.74 15404  |  \n",
    "    weighted avg  0.74  0.73  0.73 15404  |  0.78  0.74  0.74 15404  |  \n",
    "    \n",
    "    --------------------------------------+--------------------------+----------------------------\n",
    "     \n",
    "    Accuracy test set: 0.729940275253181  |      0.6929368995066216\n",
    "           > SVC  P     R     F1    S     |  P     R     F1    S     |  P     R     F1    S   \n",
    "\n",
    "        NEGATIVE  0.82  0.75  0.78  5135  |  0.77  0.65  0.71  5135  |  \n",
    "         NEUTRAL  0.82  0.58  0.68  5135  |  0.90  0.58  0.70  5135  |  \n",
    "        POSITIVE  0.63  0.86  0.73  5134  |  0.56  0.85  0.68  5134  |  \n",
    "\n",
    "        accuracy              0.73 15404  |              0.69 15404  |  \n",
    "       macro avg  0.75  0.73  0.73 15404  |  0.75  0.69  0.70 15404  |  \n",
    "    weighted avg  0.75  0.73  0.73 15404  |  0.75  0.69  0.70 15404  |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Analisis de los resultados previos + prueba de una critica random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anexo\n",
    "## Código Pregunta 1\n",
    "### Preprocesamiento del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"threads.csv\") # carga del dataset a usar como variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para convertir el rating a palabras\n",
    "def ratingTransform(rating):\n",
    "    if rating <= 2:\n",
    "        return \"NEGATIVE\"\n",
    "    elif rating <= 4:\n",
    "        return \"NEUTRAL\"\n",
    "    else:\n",
    "        return \"POSITIVE\"\n",
    "\n",
    "# creacion del grafico de pie de las reviews segun rating\n",
    "data[\"rating\"] = data[\"rating\"].apply(ratingTransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(review):\n",
    "\n",
    "    review = review.lower()\n",
    "    review = re.sub('[^a-z A-Z 0-9-]+', '', review)\n",
    "    review = \" \".join([word for word in review.split() if word not in stopwords.words('english')])\n",
    "\n",
    "    return review\n",
    "\n",
    "data['review_description'] = data['review_description'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(X,y):\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_resample, y_resample = ros.fit_resample(X, y)\n",
    "    return (X_resample, y_resample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-gram\n",
    "**Dataset sin limitaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(data[\"review_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "X_1gram = vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1gram, y1 = oversampling(X_1gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y1_test.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_1gram, y1, test_size=0.33, random_state=37,stratify=y1)\n",
    "joblib.dump(X1_train, 'modelos/X1_train.pkl')\n",
    "joblib.dump(X1_test, 'modelos/X1_test.pkl')\n",
    "joblib.dump(y1_train, 'modelos/y1_train.pkl')\n",
    "joblib.dump(y1_test, 'modelos/y1_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset con mindf = 0.0005**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=0.0005)\n",
    "vectors = vectorizer.fit_transform(data[\"review_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "X_11gram = vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_11gram, y11 = oversampling(X_11gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y11_test.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X11_train, X11_test, y11_train, y11_test = train_test_split(X_11gram, y11, test_size=0.33, random_state=37,stratify=y11)\n",
    "joblib.dump(X11_train, 'modelos/X11_train.pkl')\n",
    "joblib.dump(X11_test, 'modelos/X11_test.pkl')\n",
    "joblib.dump(y11_train, 'modelos/y11_train.pkl')\n",
    "joblib.dump(y11_test, 'modelos/y11_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar Modelos\n",
    "**Dataset sin limitaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = joblib.load('modelos/X1_train.pkl')\n",
    "y1_train = joblib.load('modelos/y1_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_DecisionTreeClassifier.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X1_train, y1_train) \n",
    "joblib.dump(clf, \"modelos/1-gram_trained_DecisionTreeClassifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_NV.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X1_train, y1_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_trained_NV.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_logistic_regesion.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X1_train, y1_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_logistic_regesion.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_svc.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X1_train, y1_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_trained_svc.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset con mindf = 0.0005**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X11_train = joblib.load('modelos/X11_train.pkl')\n",
    "y11_train = joblib.load('modelos/y11_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_DecisionTreeClassifier_md.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X11_train, y11_train) \n",
    "joblib.dump(clf, \"modelos/1-gram_trained_DecisionTreeClassifier_md.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_NV_md.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X11_train, y11_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_trained_NV_md.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_logistic_regesion_md.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X11_train, y11_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_logistic_regesion_md.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/1-gram_trained_svc_md.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X11_train, y11_train)\n",
    "joblib.dump(clf, \"modelos/1-gram_trained_svc_md.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelos para evaluar\n",
    "**Dataset sin limitaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = joblib.load('modelos/X1_test.pkl')\n",
    "y1_test = joblib.load('modelos/y1_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.753245910153207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.83      0.76      0.79      5135\n",
      "     NEUTRAL       0.76      0.74      0.75      5135\n",
      "    POSITIVE       0.69      0.76      0.73      5134\n",
      "\n",
      "    accuracy                           0.75     15404\n",
      "   macro avg       0.76      0.75      0.75     15404\n",
      "weighted avg       0.76      0.75      0.75     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_DecisionTreeClassifier.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.6999480654375487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.80      0.71      0.75      5135\n",
      "     NEUTRAL       0.68      0.56      0.62      5135\n",
      "    POSITIVE       0.64      0.83      0.72      5134\n",
      "\n",
      "    accuracy                           0.70     15404\n",
      "   macro avg       0.71      0.70      0.70     15404\n",
      "weighted avg       0.71      0.70      0.70     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_NV.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7331212672033238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.82      0.75      0.78      5135\n",
      "     NEUTRAL       0.75      0.61      0.67      5135\n",
      "    POSITIVE       0.66      0.84      0.74      5134\n",
      "\n",
      "    accuracy                           0.73     15404\n",
      "   macro avg       0.74      0.73      0.73     15404\n",
      "weighted avg       0.74      0.73      0.73     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_logistic_regesion.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.729940275253181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.82      0.75      0.78      5135\n",
      "     NEUTRAL       0.82      0.58      0.68      5135\n",
      "    POSITIVE       0.63      0.86      0.73      5134\n",
      "\n",
      "    accuracy                           0.73     15404\n",
      "   macro avg       0.75      0.73      0.73     15404\n",
      "weighted avg       0.75      0.73      0.73     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_svc.joblib\")\n",
    "y1_pred = clf.predict(X1_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y1_test, y1_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset con mindf = 0.0005**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X11_test = joblib.load('modelos/X11_test.pkl')\n",
    "y11_test = joblib.load('modelos/y11_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7290963386133472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.81      0.73      0.77      5135\n",
      "     NEUTRAL       0.74      0.69      0.72      5135\n",
      "    POSITIVE       0.65      0.76      0.70      5134\n",
      "\n",
      "    accuracy                           0.73     15404\n",
      "   macro avg       0.74      0.73      0.73     15404\n",
      "weighted avg       0.74      0.73      0.73     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_DecisionTreeClassifier_md.joblib\")\n",
    "y11_pred = clf.predict(X11_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y11_test, y11_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y11_test, y11_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.6627499350817969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.76      0.67      0.72      5135\n",
      "     NEUTRAL       0.67      0.45      0.54      5135\n",
      "    POSITIVE       0.60      0.86      0.70      5134\n",
      "\n",
      "    accuracy                           0.66     15404\n",
      "   macro avg       0.68      0.66      0.65     15404\n",
      "weighted avg       0.68      0.66      0.65     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_NV_md.joblib\")\n",
    "y11_pred = clf.predict(X11_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y11_test, y11_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y11_test, y11_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.6769021033497793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.77      0.70      0.73      5135\n",
      "     NEUTRAL       0.69      0.49      0.57      5135\n",
      "    POSITIVE       0.61      0.84      0.71      5134\n",
      "\n",
      "    accuracy                           0.68     15404\n",
      "   macro avg       0.69      0.68      0.67     15404\n",
      "weighted avg       0.69      0.68      0.67     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_logistic_regesion_md.joblib\")\n",
    "y11_pred = clf.predict(X11_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y11_test, y11_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y11_test, y11_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7174110620618022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.82      0.73      0.77      5135\n",
      "     NEUTRAL       0.80      0.55      0.65      5135\n",
      "    POSITIVE       0.61      0.87      0.72      5134\n",
      "\n",
      "    accuracy                           0.72     15404\n",
      "   macro avg       0.74      0.72      0.71     15404\n",
      "weighted avg       0.74      0.72      0.71     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/1-gram_trained_svc_md.joblib\")\n",
    "y11_pred = clf.predict(X11_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y11_test, y11_pred))   ## Evaluamos la predicción comparando y_test con y1_pred\n",
    "print(classification_report(y11_test, y11_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2,2))\n",
    "bigrams = cv.fit_transform(data['review_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = pd.DataFrame(bigrams.toarray(), columns=cv.get_feature_names_out())\n",
    "X_2gram = bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2gram, y2 = oversampling(X_2gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y2_test.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_2gram, y2, test_size=0.33, random_state=37,stratify=y2)\n",
    "joblib.dump(X2_train, 'modelos/X2_train.pkl')\n",
    "joblib.dump(X2_test, 'modelos/X2_test.pkl')\n",
    "joblib.dump(y2_train, 'modelos/y2_train.pkl')\n",
    "joblib.dump(y2_test, 'modelos/y2_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = joblib.load('modelos/X2_train.pkl')\n",
    "y2_train = joblib.load('modelos/y2_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_trained_DecisionTreeClassifier.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X2_train, y2_train) \n",
    "joblib.dump(clf, \"modelos/2-gram_trained_DecisionTreeClassifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_trained_NV.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X2_train, y2_train)\n",
    "joblib.dump(clf, \"modelos/2-gram_trained_NV.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_logistic_regesion.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X2_train, y2_train)\n",
    "joblib.dump(clf, \"modelos/2-gram_logistic_regesion.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/2-gram_trained_svc.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X2_train, y2_train)\n",
    "joblib.dump(clf, \"modelos/2-gram_trained_svc.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelos para evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_test = joblib.load('modelos/X2_test.pkl')\n",
    "y2_test = joblib.load('modelos/y2_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7294209296286679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.89      0.61      0.72      5135\n",
      "     NEUTRAL       0.84      0.70      0.76      5135\n",
      "    POSITIVE       0.59      0.88      0.71      5134\n",
      "\n",
      "    accuracy                           0.73     15404\n",
      "   macro avg       0.77      0.73      0.73     15404\n",
      "weighted avg       0.77      0.73      0.73     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_trained_DecisionTreeClassifier.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.7174759802648663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.88      0.61      0.72      5135\n",
      "     NEUTRAL       0.80      0.66      0.72      5135\n",
      "    POSITIVE       0.59      0.88      0.71      5134\n",
      "\n",
      "    accuracy                           0.72     15404\n",
      "   macro avg       0.76      0.72      0.72     15404\n",
      "weighted avg       0.76      0.72      0.72     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_trained_NV.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.738314723448455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.90      0.63      0.74      5135\n",
      "     NEUTRAL       0.84      0.68      0.75      5135\n",
      "    POSITIVE       0.61      0.91      0.73      5134\n",
      "\n",
      "    accuracy                           0.74     15404\n",
      "   macro avg       0.78      0.74      0.74     15404\n",
      "weighted avg       0.78      0.74      0.74     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_logistic_regesion.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.6929368995066216\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.77      0.65      0.71      5135\n",
      "     NEUTRAL       0.90      0.58      0.70      5135\n",
      "    POSITIVE       0.56      0.85      0.68      5134\n",
      "\n",
      "    accuracy                           0.69     15404\n",
      "   macro avg       0.75      0.69      0.70     15404\n",
      "weighted avg       0.75      0.69      0.70     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/2-gram_trained_svc.joblib\")\n",
    "y2_pred = clf.predict(X2_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y2_test, y2_pred))   ## Evaluamos la predicción comparando y2_test con y2_pred\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv1 = CountVectorizer(ngram_range=(3,3),min_df=0.00005)\n",
    "cv1 = CountVectorizer(ngram_range=(3,3))\n",
    "trigrams = cv1.fit_transform(data['review_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = pd.DataFrame(trigrams.toarray(), columns=cv1.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3gram = trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3gram, y3 = oversampling(X_3gram, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/y3_test.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X_3gram, y3, test_size=0.33, random_state=37,stratify=y3)\n",
    "joblib.dump(X3_train, 'modelos/X3_train.pkl')\n",
    "joblib.dump(X3_test, 'modelos/X3_test.pkl')\n",
    "joblib.dump(y3_train, 'modelos/y3_train.pkl')\n",
    "joblib.dump(y3_test, 'modelos/y3_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train = joblib.load('modelos/X3_train.pkl')\n",
    "y3_train = joblib.load('modelos/y3_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X3_train, y3_train) \n",
    "joblib.dump(clf, \"modelos/3-gram_trained_DecisionTreeClassifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/3-gram_trained_NV.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X3_train, y3_train)\n",
    "joblib.dump(clf, \"modelos/3-gram_trained_NV.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/3-gram_logistic_regesion.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X3_train, y3_train)\n",
    "joblib.dump(clf, \"modelos/3-gram_logistic_regesion.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelos/3-gram_trained_svc.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = SVC()\n",
    "#clf.fit(X3_train, y3_train)\n",
    "#joblib.dump(clf, \"modelos/3-gram_trained_svc.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelos para evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_test = joblib.load('modelos/X3_test.pkl')\n",
    "y3_test = joblib.load('modelos/y3_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.642235782913529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.93      0.36      0.52      5135\n",
      "     NEUTRAL       0.93      0.60      0.73      5135\n",
      "    POSITIVE       0.49      0.97      0.65      5134\n",
      "\n",
      "    accuracy                           0.64     15404\n",
      "   macro avg       0.79      0.64      0.63     15404\n",
      "weighted avg       0.79      0.64      0.63     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_trained_DecisionTreeClassifier.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.6345754349519606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.94      0.34      0.50      5135\n",
      "     NEUTRAL       0.94      0.58      0.72      5135\n",
      "    POSITIVE       0.49      0.98      0.65      5134\n",
      "\n",
      "    accuracy                           0.63     15404\n",
      "   macro avg       0.79      0.63      0.62     15404\n",
      "weighted avg       0.79      0.63      0.62     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_trained_NV.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.5246689171643729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.83      0.29      0.43      5135\n",
      "     NEUTRAL       0.77      0.35      0.48      5135\n",
      "    POSITIVE       0.43      0.94      0.59      5134\n",
      "\n",
      "    accuracy                           0.52     15404\n",
      "   macro avg       0.68      0.52      0.50     15404\n",
      "weighted avg       0.68      0.52      0.50     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"modelos/3-gram_logistic_regesion.joblib\")\n",
    "y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "print(classification_report(y3_test, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.5309010646585303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.70      0.36      0.47      5135\n",
      "     NEUTRAL       0.86      0.35      0.50      5135\n",
      "    POSITIVE       0.42      0.89      0.57      5134\n",
      "\n",
      "    accuracy                           0.53     15404\n",
      "   macro avg       0.66      0.53      0.51     15404\n",
      "weighted avg       0.66      0.53      0.51     15404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#clf = joblib.load(\"modelos/3-gram_trained_svc.joblib\")\n",
    "#y3_pred = clf.predict(X3_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "#print(\"Accuracy en test set:\", accuracy_score(y3_test, y3_pred))   ## Evaluamos la predicción comparando y3_test con y3_pred\n",
    "#print(classification_report(y3_test, y3_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
